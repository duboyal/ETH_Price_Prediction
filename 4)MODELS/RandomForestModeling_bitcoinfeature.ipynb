{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELING: Exploring the random forest regressor and classifier to predict price\n",
    "first we read in the data, and also make the classifier target list 'rise_lower' from our existing data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ultra_mega_frame = pd.read_csv('../1)DATA/df_ultra_mega_frame2.csv')\n",
    "df_ultra_mega_frame['date'] = pd.to_datetime(df_ultra_mega_frame['date'],infer_datetime_format=True)\n",
    "df_ultra_mega_frame.index = df_ultra_mega_frame['date']\n",
    "#df_ultra_mega_classifier = df_ultra_mega_frame #starting here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ultra_mega_frame['neg_count'] = df_ultra_mega_frame['neg_count']*(-1)\n",
    "df_ultra_mega_frame['neg_count'] = df_ultra_mega_frame['neg_count'] - df_ultra_mega_frame['neg_count'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ultra_mega_frame['neg_count'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ultra_mega_frame['count'] = df_ultra_mega_frame['neg_count'] + df_ultra_mega_frame['pos_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>SearchFrequency</th>\n",
       "      <th>DJI</th>\n",
       "      <th>price_btc</th>\n",
       "      <th>price_eth</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>pos_count</th>\n",
       "      <th>neg_count</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-16</th>\n",
       "      <td>2017-11-16</td>\n",
       "      <td>55</td>\n",
       "      <td>23458.359375</td>\n",
       "      <td>7871.69</td>\n",
       "      <td>330.92</td>\n",
       "      <td>0.089579</td>\n",
       "      <td>14</td>\n",
       "      <td>75</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-17</th>\n",
       "      <td>2017-11-17</td>\n",
       "      <td>75</td>\n",
       "      <td>23358.240234</td>\n",
       "      <td>7708.99</td>\n",
       "      <td>332.39</td>\n",
       "      <td>0.087821</td>\n",
       "      <td>8</td>\n",
       "      <td>59</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-18</th>\n",
       "      <td>2017-11-18</td>\n",
       "      <td>103</td>\n",
       "      <td>23358.240234</td>\n",
       "      <td>7790.15</td>\n",
       "      <td>347.61</td>\n",
       "      <td>0.092867</td>\n",
       "      <td>5</td>\n",
       "      <td>82</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-19</th>\n",
       "      <td>2017-11-19</td>\n",
       "      <td>65</td>\n",
       "      <td>23358.240234</td>\n",
       "      <td>8036.49</td>\n",
       "      <td>354.39</td>\n",
       "      <td>0.092423</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20</th>\n",
       "      <td>2017-11-20</td>\n",
       "      <td>96</td>\n",
       "      <td>23430.330078</td>\n",
       "      <td>8200.64</td>\n",
       "      <td>366.73</td>\n",
       "      <td>0.093611</td>\n",
       "      <td>7</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  SearchFrequency           DJI  price_btc  price_eth  \\\n",
       "date                                                                         \n",
       "2017-11-16 2017-11-16               55  23458.359375    7871.69     330.92   \n",
       "2017-11-17 2017-11-17               75  23358.240234    7708.99     332.39   \n",
       "2017-11-18 2017-11-18              103  23358.240234    7790.15     347.61   \n",
       "2017-11-19 2017-11-19               65  23358.240234    8036.49     354.39   \n",
       "2017-11-20 2017-11-20               96  23430.330078    8200.64     366.73   \n",
       "\n",
       "            sentiment  pos_count  neg_count  count  \n",
       "date                                                \n",
       "2017-11-16   0.089579         14         75     89  \n",
       "2017-11-17   0.087821          8         59     67  \n",
       "2017-11-18   0.092867          5         82     87  \n",
       "2017-11-19   0.092423          3         78     81  \n",
       "2017-11-20   0.093611          7         80     87  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ultra_mega_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we create 'rise_fall_list' for ethereum that will be inserted back into the dataframe to be used as a feature in the classifier model. We later do this for the other selected features as well. The features we selected were Bitcoin price, Dow Jones Index and google search frequency. Sentiment was included originally but it was deemed to return an \"importance value\" too close to zero to be considered more useful than unuseful to the model due to the curse of dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "price_list = df_ultra_mega_frame['price_eth']\n",
    "rise_fall_list = []\n",
    "\n",
    "for index, item in enumerate(df_ultra_mega_frame['price_eth']):\n",
    "    if df_ultra_mega_frame['price_eth'].iloc[index-1] < df_ultra_mega_frame['price_eth'].iloc[index]:\n",
    "        rise_fall_list.append(1)\n",
    "    else:\n",
    "        rise_fall_list.append(0)\n",
    "        \n",
    "df_ultra_mega_frame['rise_lower'] = rise_fall_list\n",
    "#df_ultra_mega_classifier = df_ultra_mega_classifier['2017-11-17':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor \n",
    "Here below we convert our y (being the target variable or label by formalism) to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array(df_ultra_mega_frame['price_btc'])\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= df_ultra_mega_frame.drop(['price_btc','date','rise_lower','pos_count','neg_count','count'], axis = 1) #'pos_count','neg_count' \n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns) #this way we remeber the column names\n",
    "# Convert to numpy array\n",
    "X = np.array(features) #because once we convert to np array it drops the names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point it's a good moment to to check X.shape and y.shape to make sure our y array is one dimensional and our X array is an 'nd array' with n corresponding to the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X.shape\n",
    "#y.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform our test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here we instantiate our Random Forest regressor. We first pick max_depth=2 and random_state=0 to begin with and then we later perform a Cv grid search to optimize the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "regr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we print out our feature importancce values to give us an idea of which feature is the most important to our model. Here we note that any features that go to zero would be considered to not play any role in improving our model. There are two features that are close to zero but still non-zero, so they technically are still marginally improving our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SearchFrequency</th>\n",
       "      <th>DJI</th>\n",
       "      <th>price_eth</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-16</th>\n",
       "      <td>55</td>\n",
       "      <td>23458.359375</td>\n",
       "      <td>330.92</td>\n",
       "      <td>0.089579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-17</th>\n",
       "      <td>75</td>\n",
       "      <td>23358.240234</td>\n",
       "      <td>332.39</td>\n",
       "      <td>0.087821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-18</th>\n",
       "      <td>103</td>\n",
       "      <td>23358.240234</td>\n",
       "      <td>347.61</td>\n",
       "      <td>0.092867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-19</th>\n",
       "      <td>65</td>\n",
       "      <td>23358.240234</td>\n",
       "      <td>354.39</td>\n",
       "      <td>0.092423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20</th>\n",
       "      <td>96</td>\n",
       "      <td>23430.330078</td>\n",
       "      <td>366.73</td>\n",
       "      <td>0.093611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            SearchFrequency           DJI  price_eth  sentiment\n",
       "date                                                           \n",
       "2017-11-16               55  23458.359375     330.92   0.089579\n",
       "2017-11-17               75  23358.240234     332.39   0.087821\n",
       "2017-11-18              103  23358.240234     347.61   0.092867\n",
       "2017-11-19               65  23358.240234     354.39   0.092423\n",
       "2017-11-20               96  23430.330078     366.73   0.093611"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.70696756  0.08228299  0.04023196  0.17051749]\n",
      "[ search frequency, dow jones index, ethereum price, sentiment ] \n"
     ]
    }
   ],
   "source": [
    "print(regr.feature_importances_) #strength of importance of feature in the model\n",
    "#but is using the other two because they are not zero!!!\n",
    "print('[ search frequency, dow jones index, ethereum price, sentiment ] ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above numbers signify the following features respectivley\n",
    "\n",
    "1)  search frequency\n",
    "2)  Dow Jones Index\n",
    "3)  eth Price \n",
    "4)  sentiment\n",
    "\n",
    "\n",
    "We originally had input a feature column of the polarity score of Ethereum sentiment for each day (all reddit data that was scraped) and then another as well a feature called pos_count and  feature went to zero so we chose not to include it in our model.\n",
    "\n",
    "when you have more features, you are basically saying you need more data to adequetly sample the space or else you run into the curse of dimensionality. This is what tells you that for the more dimenions you have, you need more data in total in order to sample your entire space. What do you run the risk of otherwise? of being innaccurate. in which way? in the way that your data set you have doesnt adequatley cover sample space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10218.15140696  12027.05279176   9391.31213794  12951.5302241\n",
      "  10218.15140696  13287.14166641  14577.51695743  13993.6903141\n",
      "   9248.74669151  12469.32205362   8630.09629417  10218.15140696\n",
      "  14577.51695743  10218.15140696  12645.2844641   14241.90551512\n",
      "  11489.73215353   8630.09629417  13993.6903141   12027.05279176\n",
      "  10029.16630393  14577.51695743  12143.15474271   8630.09629417\n",
      "  13993.6903141   12726.98138604  12951.5302241   14577.51695743\n",
      "  10029.16630393   9248.74669151  14577.51695743  12469.32205362]\n"
     ]
    }
   ],
   "source": [
    "print(regr.predict(X_test)) #predict y given x test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above: X_test is the argument taken in, but the output for the predict function is only one dimension just like y. We can later graph this result from predict against Y test to explicitly see if our model worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4145162077636052"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now can compare with the original X and Y_train!!!\n",
    "#using score \n",
    "regr.score(X_test, Y_test) #X_test , as seen above...X_test has more dimensions than the output on predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This score returns an r squared value. It is a percentage, how well the variablity of your data is captured by a given model comparisons betweeen different models scores tells you which model is better.\n",
    "\n",
    "below we perform a CV grid search across the following parameters: \"criterion\": [\"mse\", \"mae\"], \"max_depth\": [2, 6, 8], \"n_estimators\":[50, 100, 200], and we optimize our score based off of the grid search. We also see that we perporm a cross validation of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'criterion': ['mse', 'mae'], 'max_depth': [2, 6, 8], 'n_estimators': [50, 100, 200]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use a grid search\n",
    "param_grid = {\"criterion\": [\"mse\", \"mae\"], #mean squared error and mean absolute error in documentation\n",
    "              #\"min_samples_split\": [10, 20, 40],\n",
    "              \"max_depth\": [2, 6, 8],\n",
    "              \"n_estimators\":[50, 100, 200]\n",
    "              #\"min_samples_leaf\": [20, 40, 100],\n",
    "              #\"max_leaf_nodes\": [5, 20, 100, 500, 800],\n",
    "              }\n",
    "\n",
    "grid_cv_regr = GridSearchCV(regr, param_grid, cv=5)\n",
    "\n",
    "grid_cv_regr.fit(X_train, Y_train) #features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Squared::0.46207896516203917\n",
      "Best Hyperparameters::\n",
      "{'criterion': 'mae', 'max_depth': 8, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(\"R-Squared::{}\".format(grid_cv_regr.best_score_))\n",
    "print(\"Best Hyperparameters::\\n{}\".format(grid_cv_regr.best_params_))\n",
    "\n",
    "#random forest builds multiple decision trees \n",
    "#best number of decision trees\n",
    "#depth of each tree shouldnt be more than 8 levels\n",
    "#go down to 8 levels(splits) but dont split it further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How is it that after the hyperparameter tuning, our R squared went down? difference between rsquared is that this one tells how well did this model work for hyperparametrization on the train data, because we dont give it the test data. You don't want any part of you model to be trained on the test data. So this part is NOT the same R squared from our score output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alexandra/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Alexandra/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Alexandra/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Alexandra/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Alexandra/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Alexandra/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Alexandra/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051319</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>0.281789</td>\n",
       "      <td>0.631256</td>\n",
       "      <td>mse</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.477109</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.142404</td>\n",
       "      <td>0.644288</td>\n",
       "      <td>0.500170</td>\n",
       "      <td>0.602634</td>\n",
       "      <td>0.363442</td>\n",
       "      <td>0.627618</td>\n",
       "      <td>0.004937</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.236436</td>\n",
       "      <td>0.021415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.087565</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.292897</td>\n",
       "      <td>0.630943</td>\n",
       "      <td>mse</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>13</td>\n",
       "      <td>0.475486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.105999</td>\n",
       "      <td>0.651542</td>\n",
       "      <td>0.501014</td>\n",
       "      <td>0.598214</td>\n",
       "      <td>0.375078</td>\n",
       "      <td>0.624155</td>\n",
       "      <td>0.009879</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.223450</td>\n",
       "      <td>0.023255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.168977</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>0.280547</td>\n",
       "      <td>0.633430</td>\n",
       "      <td>mse</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.475172</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069913</td>\n",
       "      <td>0.655025</td>\n",
       "      <td>0.498987</td>\n",
       "      <td>0.597950</td>\n",
       "      <td>0.326435</td>\n",
       "      <td>0.627848</td>\n",
       "      <td>0.012793</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>0.211671</td>\n",
       "      <td>0.023955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.044190</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>0.444395</td>\n",
       "      <td>0.908470</td>\n",
       "      <td>mse</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'n_estima...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.618510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176467</td>\n",
       "      <td>0.914117</td>\n",
       "      <td>0.700309</td>\n",
       "      <td>0.901422</td>\n",
       "      <td>0.393833</td>\n",
       "      <td>0.906833</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.192356</td>\n",
       "      <td>0.004283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.098540</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>0.451647</td>\n",
       "      <td>0.912300</td>\n",
       "      <td>mse</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'n_estima...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.631816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162958</td>\n",
       "      <td>0.920454</td>\n",
       "      <td>0.670605</td>\n",
       "      <td>0.899347</td>\n",
       "      <td>0.433452</td>\n",
       "      <td>0.911316</td>\n",
       "      <td>0.013749</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.186860</td>\n",
       "      <td>0.007101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.051319         0.002465         0.281789          0.631256   \n",
       "1       0.087565         0.003652         0.292897          0.630943   \n",
       "2       0.168977         0.007679         0.280547          0.633430   \n",
       "3       0.044190         0.001998         0.444395          0.908470   \n",
       "4       0.098540         0.004598         0.451647          0.912300   \n",
       "\n",
       "  param_criterion param_max_depth param_n_estimators  \\\n",
       "0             mse               2                 50   \n",
       "1             mse               2                100   \n",
       "2             mse               2                200   \n",
       "3             mse               6                 50   \n",
       "4             mse               6                100   \n",
       "\n",
       "                                              params  rank_test_score  \\\n",
       "0  {'criterion': 'mse', 'max_depth': 2, 'n_estima...               14   \n",
       "1  {'criterion': 'mse', 'max_depth': 2, 'n_estima...               13   \n",
       "2  {'criterion': 'mse', 'max_depth': 2, 'n_estima...               15   \n",
       "3  {'criterion': 'mse', 'max_depth': 6, 'n_estima...               10   \n",
       "4  {'criterion': 'mse', 'max_depth': 6, 'n_estima...                6   \n",
       "\n",
       "   split0_test_score       ...         split2_test_score  split2_train_score  \\\n",
       "0           0.477109       ...                 -0.142404            0.644288   \n",
       "1           0.475486       ...                 -0.105999            0.651542   \n",
       "2           0.475172       ...                 -0.069913            0.655025   \n",
       "3           0.618510       ...                  0.176467            0.914117   \n",
       "4           0.631816       ...                  0.162958            0.920454   \n",
       "\n",
       "   split3_test_score  split3_train_score  split4_test_score  \\\n",
       "0           0.500170            0.602634           0.363442   \n",
       "1           0.501014            0.598214           0.375078   \n",
       "2           0.498987            0.597950           0.326435   \n",
       "3           0.700309            0.901422           0.393833   \n",
       "4           0.670605            0.899347           0.433452   \n",
       "\n",
       "   split4_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0            0.627618      0.004937        0.000614        0.236436   \n",
       "1            0.624155      0.009879        0.000225        0.223450   \n",
       "2            0.627848      0.012793        0.001177        0.211671   \n",
       "3            0.906833      0.001032        0.000044        0.192356   \n",
       "4            0.911316      0.013749        0.001934        0.186860   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.021415  \n",
       "1         0.023255  \n",
       "2         0.023955  \n",
       "3         0.004283  \n",
       "4         0.007101  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=grid_cv_regr.cv_results_)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'mse', 'max_depth': 2, 'n_estimators': 50} 0.2818 0.2364\n",
      "{'criterion': 'mse', 'max_depth': 2, 'n_estimators': 100} 0.2929 0.2234\n",
      "{'criterion': 'mse', 'max_depth': 2, 'n_estimators': 200} 0.2805 0.2117\n",
      "{'criterion': 'mse', 'max_depth': 6, 'n_estimators': 50} 0.4444 0.1924\n",
      "{'criterion': 'mse', 'max_depth': 6, 'n_estimators': 100} 0.4516 0.1869\n",
      "{'criterion': 'mse', 'max_depth': 6, 'n_estimators': 200} 0.4584 0.185\n",
      "{'criterion': 'mse', 'max_depth': 8, 'n_estimators': 50} 0.4414 0.1951\n",
      "{'criterion': 'mse', 'max_depth': 8, 'n_estimators': 100} 0.449 0.1869\n",
      "{'criterion': 'mse', 'max_depth': 8, 'n_estimators': 200} 0.4509 0.1946\n",
      "{'criterion': 'mae', 'max_depth': 2, 'n_estimators': 50} 0.2435 0.2583\n",
      "{'criterion': 'mae', 'max_depth': 2, 'n_estimators': 100} 0.2503 0.254\n",
      "{'criterion': 'mae', 'max_depth': 2, 'n_estimators': 200} 0.2467 0.2547\n",
      "{'criterion': 'mae', 'max_depth': 6, 'n_estimators': 50} 0.4436 0.1594\n",
      "{'criterion': 'mae', 'max_depth': 6, 'n_estimators': 100} 0.4471 0.1683\n",
      "{'criterion': 'mae', 'max_depth': 6, 'n_estimators': 200} 0.4528 0.1658\n",
      "{'criterion': 'mae', 'max_depth': 8, 'n_estimators': 50} 0.4608 0.1819\n",
      "{'criterion': 'mae', 'max_depth': 8, 'n_estimators': 100} 0.4621 0.1792\n",
      "{'criterion': 'mae', 'max_depth': 8, 'n_estimators': 200} 0.4619 0.1792\n"
     ]
    }
   ],
   "source": [
    "results = grid_cv_regr.cv_results_\n",
    "for param, score_mean, score_sd in zip(results['params'], results['mean_test_score'], results['std_test_score']):\n",
    "    print(param, round(score_mean, 4), round(score_sd, 4))\n",
    "    \n",
    "#the highest is n=100, and mx depth 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61763232252078237"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_regr.score(X_test, Y_test) #this is really great!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a good score! since the feature of 'sentiment' was so close to zero, lets see if removing the feasture improves the accuracy of the model! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now compare to dropping features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array(df_ultra_mega_frame['price_btc'])\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= df_ultra_mega_frame.drop(['price_btc','date','rise_lower','sentiment','pos_count', 'neg_count',\n",
    "       'count'], axis = 1)\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns) #this way we remeber the column names\n",
    "# Convert to numpy array\n",
    "X = np.array(features) #because once we convert to np array it drops the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "regr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SearchFrequency</th>\n",
       "      <th>DJI</th>\n",
       "      <th>price_eth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-16</th>\n",
       "      <td>55</td>\n",
       "      <td>23458.359375</td>\n",
       "      <td>330.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-17</th>\n",
       "      <td>75</td>\n",
       "      <td>23358.240234</td>\n",
       "      <td>332.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-18</th>\n",
       "      <td>103</td>\n",
       "      <td>23358.240234</td>\n",
       "      <td>347.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-19</th>\n",
       "      <td>65</td>\n",
       "      <td>23358.240234</td>\n",
       "      <td>354.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20</th>\n",
       "      <td>96</td>\n",
       "      <td>23430.330078</td>\n",
       "      <td>366.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            SearchFrequency           DJI  price_eth\n",
       "date                                                \n",
       "2017-11-16               55  23458.359375     330.92\n",
       "2017-11-17               75  23358.240234     332.39\n",
       "2017-11-18              103  23358.240234     347.61\n",
       "2017-11-19               65  23358.240234     354.39\n",
       "2017-11-20               96  23430.330078     366.73"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.78888708  0.12048072  0.0906322 ]\n"
     ]
    }
   ],
   "source": [
    "print(regr.feature_importances_) #strength of importance of feature in the model\n",
    "#but is using the other two because they are not zero!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = features.drop(['SearchFrequency'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10218.15140696  11646.94362747   9391.31213794  12598.22137089\n",
      "  10218.15140696  12763.78706319  14054.16235422  14029.78331753\n",
      "   9248.74669151  12398.79246615   8630.09629417  10218.15140696\n",
      "  15344.13119516  10218.15140696  14029.78331753  13984.14960026\n",
      "  11392.94790135   8630.09629417  14029.78331753  11646.94362747\n",
      "  10029.16630393  15344.13119516  12072.62515523   8630.09629417\n",
      "  14029.78331753  12656.45179856  12598.22137089  14149.71529256\n",
      "  10029.16630393   9248.74669151  14613.60996086  12089.21288934]\n"
     ]
    }
   ],
   "source": [
    "print(regr.predict(X_test)) #predict y given x test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39714319785793684"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now can compare with the original X_train!!!\n",
    "#using score \n",
    "regr.score(X_test, Y_test) #X_test , as seen above...X_test has more dimensions than the output on predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'criterion': ['mse', 'mae'], 'max_depth': [2, 6, 8], 'n_estimators': [50, 100, 200]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use a grid search\n",
    "param_grid = {\"criterion\": [\"mse\", \"mae\"], #mean squared error and mean absolute error in documentation\n",
    "              #\"min_samples_split\": [10, 20, 40],\n",
    "              \"max_depth\": [2, 6, 8],\n",
    "              \"n_estimators\":[50, 100, 200]\n",
    "              #\"min_samples_leaf\": [20, 40, 100],\n",
    "              #\"max_leaf_nodes\": [5, 20, 100, 500, 800],\n",
    "              }\n",
    "\n",
    "grid_cv_regr = GridSearchCV(regr, param_grid, cv=5)\n",
    "\n",
    "grid_cv_regr.fit(X_train, Y_train) #features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 11569.861725  ,  11524.81025   ,   9889.18223265,  11550.75105891,\n",
       "        10894.78300585,  11516.75894403,  15073.20455873,  16228.23325   ,\n",
       "         9019.69323976,  14071.4280369 ,   8117.8678919 ,   9966.91228156,\n",
       "        16783.89933333,  10504.80119982,  14380.16088571,  13441.77838333,\n",
       "        11752.53242815,   9267.68518667,  15614.93475   ,  11241.73005   ,\n",
       "        12087.89637429,  16772.47833333,  11915.89012464,   7869.49807167,\n",
       "        13917.28935   ,  14101.46131071,  11249.20701447,  13002.62184167,\n",
       "         9790.14021431,   8814.96342318,  16288.07643333,  12505.52185   ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_regr.predict(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the output and notice that its one dimensional which is what we want. We now set this variable to Y_predicted so that we can later graph it against Y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_predicted = grid_cv_regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Squared::0.37900769548512786\n",
      "Best Hyperparameters::\n",
      "{'criterion': 'mse', 'max_depth': 8, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(\"R-Squared::{}\".format(grid_cv_regr.best_score_))\n",
    "print(\"Best Hyperparameters::\\n{}\".format(grid_cv_regr.best_params_))\n",
    "\n",
    "#random forest builds multiple decision trees \n",
    "#best number of decision trees\n",
    "#depth of each tree shouldnt be more than 8 levels\n",
    "#go down to 8 levels(splits) but dont split it further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alexandra/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Alexandra/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Alexandra/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Alexandra/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Alexandra/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Alexandra/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Alexandra/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.070985</td>\n",
       "      <td>0.002798</td>\n",
       "      <td>0.274062</td>\n",
       "      <td>0.597377</td>\n",
       "      <td>mse</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.428732</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179742</td>\n",
       "      <td>0.641213</td>\n",
       "      <td>0.489674</td>\n",
       "      <td>0.568852</td>\n",
       "      <td>0.320574</td>\n",
       "      <td>0.613197</td>\n",
       "      <td>0.017205</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.237880</td>\n",
       "      <td>0.026996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.088372</td>\n",
       "      <td>0.004110</td>\n",
       "      <td>0.289419</td>\n",
       "      <td>0.598404</td>\n",
       "      <td>mse</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.444463</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.140780</td>\n",
       "      <td>0.648843</td>\n",
       "      <td>0.498335</td>\n",
       "      <td>0.564465</td>\n",
       "      <td>0.336237</td>\n",
       "      <td>0.611329</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.227168</td>\n",
       "      <td>0.030292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.161218</td>\n",
       "      <td>0.006586</td>\n",
       "      <td>0.279534</td>\n",
       "      <td>0.600846</td>\n",
       "      <td>mse</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.450480</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127505</td>\n",
       "      <td>0.651418</td>\n",
       "      <td>0.491253</td>\n",
       "      <td>0.564375</td>\n",
       "      <td>0.287447</td>\n",
       "      <td>0.614598</td>\n",
       "      <td>0.003955</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.220284</td>\n",
       "      <td>0.030917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.043455</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.354669</td>\n",
       "      <td>0.899598</td>\n",
       "      <td>mse</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'n_estima...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.603385</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075085</td>\n",
       "      <td>0.898681</td>\n",
       "      <td>0.572687</td>\n",
       "      <td>0.899897</td>\n",
       "      <td>0.213247</td>\n",
       "      <td>0.904443</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.255291</td>\n",
       "      <td>0.003173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.084787</td>\n",
       "      <td>0.003732</td>\n",
       "      <td>0.361048</td>\n",
       "      <td>0.903620</td>\n",
       "      <td>mse</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'n_estima...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.588669</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071980</td>\n",
       "      <td>0.899941</td>\n",
       "      <td>0.563464</td>\n",
       "      <td>0.899982</td>\n",
       "      <td>0.255444</td>\n",
       "      <td>0.912810</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.246854</td>\n",
       "      <td>0.004997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.070985         0.002798         0.274062          0.597377   \n",
       "1       0.088372         0.004110         0.289419          0.598404   \n",
       "2       0.161218         0.006586         0.279534          0.600846   \n",
       "3       0.043455         0.002114         0.354669          0.899598   \n",
       "4       0.084787         0.003732         0.361048          0.903620   \n",
       "\n",
       "  param_criterion param_max_depth param_n_estimators  \\\n",
       "0             mse               2                 50   \n",
       "1             mse               2                100   \n",
       "2             mse               2                200   \n",
       "3             mse               6                 50   \n",
       "4             mse               6                100   \n",
       "\n",
       "                                              params  rank_test_score  \\\n",
       "0  {'criterion': 'mse', 'max_depth': 2, 'n_estima...               14   \n",
       "1  {'criterion': 'mse', 'max_depth': 2, 'n_estima...               11   \n",
       "2  {'criterion': 'mse', 'max_depth': 2, 'n_estima...               12   \n",
       "3  {'criterion': 'mse', 'max_depth': 6, 'n_estima...                5   \n",
       "4  {'criterion': 'mse', 'max_depth': 6, 'n_estima...                4   \n",
       "\n",
       "   split0_test_score       ...         split2_test_score  split2_train_score  \\\n",
       "0           0.428732       ...                 -0.179742            0.641213   \n",
       "1           0.444463       ...                 -0.140780            0.648843   \n",
       "2           0.450480       ...                 -0.127505            0.651418   \n",
       "3           0.603385       ...                 -0.075085            0.898681   \n",
       "4           0.588669       ...                 -0.071980            0.899941   \n",
       "\n",
       "   split3_test_score  split3_train_score  split4_test_score  \\\n",
       "0           0.489674            0.568852           0.320574   \n",
       "1           0.498335            0.564465           0.336237   \n",
       "2           0.491253            0.564375           0.287447   \n",
       "3           0.572687            0.899897           0.213247   \n",
       "4           0.563464            0.899982           0.255444   \n",
       "\n",
       "   split4_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0            0.613197      0.017205        0.000786        0.237880   \n",
       "1            0.611329      0.004634        0.000517        0.227168   \n",
       "2            0.614598      0.003955        0.000047        0.220284   \n",
       "3            0.904443      0.002584        0.000213        0.255291   \n",
       "4            0.912810      0.001855        0.000182        0.246854   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.026996  \n",
       "1         0.030292  \n",
       "2         0.030917  \n",
       "3         0.003173  \n",
       "4         0.004997  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=grid_cv_regr.cv_results_)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'mse', 'max_depth': 2, 'n_estimators': 50} 0.2741 0.2379\n",
      "{'criterion': 'mse', 'max_depth': 2, 'n_estimators': 100} 0.2894 0.2272\n",
      "{'criterion': 'mse', 'max_depth': 2, 'n_estimators': 200} 0.2795 0.2203\n",
      "{'criterion': 'mse', 'max_depth': 6, 'n_estimators': 50} 0.3547 0.2553\n",
      "{'criterion': 'mse', 'max_depth': 6, 'n_estimators': 100} 0.361 0.2469\n",
      "{'criterion': 'mse', 'max_depth': 6, 'n_estimators': 200} 0.3493 0.2509\n",
      "{'criterion': 'mse', 'max_depth': 8, 'n_estimators': 50} 0.3702 0.2443\n",
      "{'criterion': 'mse', 'max_depth': 8, 'n_estimators': 100} 0.379 0.2303\n",
      "{'criterion': 'mse', 'max_depth': 8, 'n_estimators': 200} 0.363 0.2429\n",
      "{'criterion': 'mae', 'max_depth': 2, 'n_estimators': 50} 0.2392 0.2519\n",
      "{'criterion': 'mae', 'max_depth': 2, 'n_estimators': 100} 0.2495 0.2508\n",
      "{'criterion': 'mae', 'max_depth': 2, 'n_estimators': 200} 0.2501 0.2606\n",
      "{'criterion': 'mae', 'max_depth': 6, 'n_estimators': 50} 0.2742 0.2473\n",
      "{'criterion': 'mae', 'max_depth': 6, 'n_estimators': 100} 0.3115 0.2325\n",
      "{'criterion': 'mae', 'max_depth': 6, 'n_estimators': 200} 0.3213 0.2411\n",
      "{'criterion': 'mae', 'max_depth': 8, 'n_estimators': 50} 0.2725 0.2343\n",
      "{'criterion': 'mae', 'max_depth': 8, 'n_estimators': 100} 0.3189 0.2166\n",
      "{'criterion': 'mae', 'max_depth': 8, 'n_estimators': 200} 0.323 0.2377\n"
     ]
    }
   ],
   "source": [
    "results = grid_cv_regr.cv_results_\n",
    "for param, score_mean, score_sd in zip(results['params'], results['mean_test_score'], results['std_test_score']):\n",
    "    print(param, round(score_mean, 4), round(score_sd, 4))\n",
    "    \n",
    "#the highest is n=100, and mx depth 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60821364342307183"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_regr.score(X_test, Y_test) #this is really great!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we see that hyperparameterization worked!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnQAAAF6CAYAAACQi8UiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(Y_test, alpha = 1)\n",
    "plt.plot(Y_predicted, alpha = 1)\n",
    "\n",
    "plt.title('Predicted Bitcoin Price vs. Test set Price')\n",
    "\n",
    "# need to add legend\n",
    "plt.ylabel('price in dollars')\n",
    "plt.xticks(rotation=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid_cv_regr.score(X_test, Y_test), performs the same thing, (notice the number is the same) it runs the model again with the optimized parameters\n",
    "\n",
    "Note: this doesn't forcast what is to come. This model tells us How changes in the Dow Jones (and other features) might cause changes in ethereum. If you can use Time series analysis to forecast changes in the dow jones, you might be able to predict changes in ethereum, but you dont have the ability to do forecasting with this model.\n",
    "\n",
    "Can A Regression model forecast? The most you can forcast Is If you predicted dow jones values and fed that prediction into a model to forcast ethereum price. Dow jones index has a lot of historical data backing it up as opposed to etheruem, so thats why it could posible be used as an exogeneous variable in a time series model (ARIMAX was looked into breifly for this prroject and more will be included on that.\n",
    "\n",
    "A classification model can be put into place in order to predict if the price of ethereum will go up or down. In order to do this all of the features that are deemed significant must also be converted to a binary list of 0's or 1's. A 0 signifying that the price dropped since the day before and a 1 signifying that the price rose since then.\n",
    "\n",
    "We will now look at classification and for this we weill drop the sentiment feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now for classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df_ultra_mega_frame['rise_lower']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array(df_ultra_mega_frame['rise_lower'])\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= df_ultra_mega_frame.drop(['date','rise_lower','price_eth','sentiment'], axis = 1)\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns) #this way we remeber the column names\n",
    "# Convert to numpy array\n",
    "X = np.array(features) #because once we convert to np array it drops the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#features #toggle this to double check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06095095, 0.29641318, 0.29611777, 0.        , 0.11169043,\n",
       "       0.23482766])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [2, 6, 8], 'n_estimators': [50, 100, 200]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use a grid search\n",
    "\n",
    "param_grid = {#\"criterion\": [\"mse\", \"mae\"], #mean squared error and mean absolute error in documentation\n",
    "              #\"min_samples_split\": [10, 20, 40],\n",
    "              \"max_depth\": [2, 6, 8],\n",
    "              \"n_estimators\":[50, 100, 200]\n",
    "              #\"min_samples_leaf\": [20, 40, 100],\n",
    "              #\"max_leaf_nodes\": [5, 20, 100, 500, 800],\n",
    "              }\n",
    "\n",
    "grid_cv_clf = GridSearchCV(clf, param_grid, cv=5)\n",
    "grid_cv_clf.fit(X_train, Y_train) #features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Squared::0.37900769548512786\n",
      "Best Hyperparameters::\n",
      "{'criterion': 'mse', 'max_depth': 8, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(\"R-Squared::{}\".format(grid_cv_regr.best_score_))\n",
    "print(\"Best Hyperparameters::\\n{}\".format(grid_cv_regr.best_params_))\n",
    "\n",
    "#random forest builds multiple decision trees \n",
    "#best number of decision trees\n",
    "#depth of each tree shouldnt be more than 8 levels\n",
    "#go down to 8 levels(splits) but dont split it further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.056532</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>0.274062</td>\n",
       "      <td>0.597377</td>\n",
       "      <td>mse</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>13</td>\n",
       "      <td>0.428732</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179742</td>\n",
       "      <td>0.641213</td>\n",
       "      <td>0.489674</td>\n",
       "      <td>0.568852</td>\n",
       "      <td>0.320574</td>\n",
       "      <td>0.613197</td>\n",
       "      <td>0.010193</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.237880</td>\n",
       "      <td>0.026996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.082384</td>\n",
       "      <td>0.005549</td>\n",
       "      <td>0.289419</td>\n",
       "      <td>0.598404</td>\n",
       "      <td>mse</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.444463</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.140780</td>\n",
       "      <td>0.648843</td>\n",
       "      <td>0.498335</td>\n",
       "      <td>0.564465</td>\n",
       "      <td>0.336237</td>\n",
       "      <td>0.611329</td>\n",
       "      <td>0.003168</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.227168</td>\n",
       "      <td>0.030292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.159318</td>\n",
       "      <td>0.008858</td>\n",
       "      <td>0.279534</td>\n",
       "      <td>0.600846</td>\n",
       "      <td>mse</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.450480</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127505</td>\n",
       "      <td>0.651418</td>\n",
       "      <td>0.491253</td>\n",
       "      <td>0.564375</td>\n",
       "      <td>0.287447</td>\n",
       "      <td>0.614598</td>\n",
       "      <td>0.008569</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.220284</td>\n",
       "      <td>0.030917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.041140</td>\n",
       "      <td>0.002636</td>\n",
       "      <td>0.354669</td>\n",
       "      <td>0.899598</td>\n",
       "      <td>mse</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'n_estima...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.603385</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075085</td>\n",
       "      <td>0.898681</td>\n",
       "      <td>0.572687</td>\n",
       "      <td>0.899897</td>\n",
       "      <td>0.213247</td>\n",
       "      <td>0.904443</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.255291</td>\n",
       "      <td>0.003173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.082977</td>\n",
       "      <td>0.004686</td>\n",
       "      <td>0.361048</td>\n",
       "      <td>0.903620</td>\n",
       "      <td>mse</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'n_estima...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.588669</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071980</td>\n",
       "      <td>0.899941</td>\n",
       "      <td>0.563464</td>\n",
       "      <td>0.899982</td>\n",
       "      <td>0.255444</td>\n",
       "      <td>0.912810</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.246854</td>\n",
       "      <td>0.004997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.056532         0.004241         0.274062          0.597377   \n",
       "1       0.082384         0.005549         0.289419          0.598404   \n",
       "2       0.159318         0.008858         0.279534          0.600846   \n",
       "3       0.041140         0.002636         0.354669          0.899598   \n",
       "4       0.082977         0.004686         0.361048          0.903620   \n",
       "\n",
       "  param_criterion param_max_depth param_n_estimators  \\\n",
       "0             mse               2                 50   \n",
       "1             mse               2                100   \n",
       "2             mse               2                200   \n",
       "3             mse               6                 50   \n",
       "4             mse               6                100   \n",
       "\n",
       "                                              params  rank_test_score  \\\n",
       "0  {'criterion': 'mse', 'max_depth': 2, 'n_estima...               13   \n",
       "1  {'criterion': 'mse', 'max_depth': 2, 'n_estima...               11   \n",
       "2  {'criterion': 'mse', 'max_depth': 2, 'n_estima...               12   \n",
       "3  {'criterion': 'mse', 'max_depth': 6, 'n_estima...                5   \n",
       "4  {'criterion': 'mse', 'max_depth': 6, 'n_estima...                4   \n",
       "\n",
       "   split0_test_score       ...         split2_test_score  split2_train_score  \\\n",
       "0           0.428732       ...                 -0.179742            0.641213   \n",
       "1           0.444463       ...                 -0.140780            0.648843   \n",
       "2           0.450480       ...                 -0.127505            0.651418   \n",
       "3           0.603385       ...                 -0.075085            0.898681   \n",
       "4           0.588669       ...                 -0.071980            0.899941   \n",
       "\n",
       "   split3_test_score  split3_train_score  split4_test_score  \\\n",
       "0           0.489674            0.568852           0.320574   \n",
       "1           0.498335            0.564465           0.336237   \n",
       "2           0.491253            0.564375           0.287447   \n",
       "3           0.572687            0.899897           0.213247   \n",
       "4           0.563464            0.899982           0.255444   \n",
       "\n",
       "   split4_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0            0.613197      0.010193        0.001200        0.237880   \n",
       "1            0.611329      0.003168        0.000946        0.227168   \n",
       "2            0.614598      0.008569        0.000379        0.220284   \n",
       "3            0.904443      0.001016        0.000155        0.255291   \n",
       "4            0.912810      0.002094        0.000108        0.246854   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.026996  \n",
       "1         0.030292  \n",
       "2         0.030917  \n",
       "3         0.003173  \n",
       "4         0.004997  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=grid_cv_regr.cv_results_)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46875"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It feels as if what we did here was comparing apples and oranges. Comparing apples with apples would be more like, did dow jones increase? did google search frequency increase? a score around 50 percent is actually a likely result here, because this is a binary target, and nothing in my features say anything about the previous day. Here we are taking a bunch of values and trying to figure out weather these values were higher or lower than the previous day, but we have no information about the previous day in our dfeatures matrix. For example when looking at one line of data from our features matrix, does any cell in this line tell us something about the previous day? On any given line how does it compare to the one before it? All these values are independent from the day before, acording to my model, because we are not saying how they are related.\n",
    "\n",
    "Now we will explore another idea for a classifier. For every single feature, make it an up or down binary vector. We should get way better results because we are not simply flipping a coin anymore. The binary of dow jones having gone up or down up or down should be more predictive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Classification with binary features:\n",
    "first we will make some binary features from lists utilizing the enumerate function. What the binary representation will indicate is the following: if the value went up from the day before we will attribute a 1 to that value. Each element in the vector is saying something about what direction price went from the day before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rise_fall_list_DJI = []\n",
    "\n",
    "for index, item in enumerate(df_ultra_mega_frame['DJI']):\n",
    "    if df_ultra_mega_frame['DJI'].iloc[index-1] < df_ultra_mega_frame['DJI'].iloc[index]:\n",
    "        rise_fall_list_DJI.append(1)\n",
    "    else:\n",
    "        rise_fall_list_DJI.append(0)\n",
    "        \n",
    "\n",
    "df_ultra_mega_frame['rise_lower_dji'] = rise_fall_list_DJI\n",
    "\n",
    "#--------\n",
    "rise_fall_list_BTC = []\n",
    "\n",
    "for index, item in enumerate(df_ultra_mega_frame['price_btc']):\n",
    "    if df_ultra_mega_frame['price_btc'].iloc[index-1] < df_ultra_mega_frame['price_btc'].iloc[index]:\n",
    "        rise_fall_list_BTC.append(1)\n",
    "    else:\n",
    "        rise_fall_list_BTC.append(0)\n",
    "        \n",
    "\n",
    "df_ultra_mega_frame['rise_lower_btc'] = rise_fall_list_BTC\n",
    "\n",
    "#---------\n",
    "rise_fall_list_SF = []\n",
    "\n",
    "for index, item in enumerate(df_ultra_mega_frame['SearchFrequency']):\n",
    "    if df_ultra_mega_frame['SearchFrequency'].iloc[index-1] < df_ultra_mega_frame['SearchFrequency'].iloc[index]:\n",
    "        rise_fall_list_SF.append(1)\n",
    "    else:\n",
    "        rise_fall_list_SF.append(0)\n",
    "        \n",
    "\n",
    "df_ultra_mega_frame['rise_lower_sf'] = rise_fall_list_SF\n",
    "\n",
    "df_ultra_mega_frame = df_ultra_mega_frame['2017-11-17':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that at the bottom of this code block we chop off the first line of the data frame because at this pint we are only dealing with the binary features and we do not have information to say whether the first element of our data set rose in price or fell in price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df_ultra_mega_frame['rise_lower'] #setting our label y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array(df_ultra_mega_frame['rise_lower'])\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= df_ultra_mega_frame.filter(['rise_lower_dji','rise_lower_btc','rise_lower_sf'], axis = 1)\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns) #this way we remeber the column names\n",
    "# Convert to numpy array\n",
    "X = np.array(features) #because once we convert to np array it drops the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12937936, 0.78567976, 0.08494088])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6875"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [2, 6, 8], 'n_estimators': [50, 100, 200]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use a grid search\n",
    "\n",
    "param_grid = {#\"criterion\": [\"mse\", \"mae\"], #mean squared error and mean absolute error in documentation\n",
    "              #\"min_samples_split\": [10, 20, 40],\n",
    "              \"max_depth\": [2, 6, 8],\n",
    "              \"n_estimators\":[50, 100, 200]\n",
    "              #\"min_samples_leaf\": [20, 40, 100],\n",
    "              #\"max_leaf_nodes\": [5, 20, 100, 500, 800],\n",
    "              }\n",
    "\n",
    "grid_cv_clf = GridSearchCV(clf, param_grid, cv=5)\n",
    "\n",
    "grid_cv_clf.fit(X_train, Y_train) #features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Squared::0.37900769548512786\n",
      "Best Hyperparameters::\n",
      "{'criterion': 'mse', 'max_depth': 8, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(\"R-Squared::{}\".format(grid_cv_regr.best_score_))\n",
    "print(\"Best Hyperparameters::\\n{}\".format(grid_cv_regr.best_params_))\n",
    "\n",
    "#random forest builds multiple decision trees \n",
    "#best number of decision trees\n",
    "#depth of each tree shouldnt be more than 8 levels\n",
    "#go down to 8 levels(splits) but dont split it further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.047817</td>\n",
       "      <td>0.003355</td>\n",
       "      <td>0.635309</td>\n",
       "      <td>0.778977</td>\n",
       "      <td>mse</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.613964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451744</td>\n",
       "      <td>0.804077</td>\n",
       "      <td>0.656762</td>\n",
       "      <td>0.758853</td>\n",
       "      <td>0.675603</td>\n",
       "      <td>0.792493</td>\n",
       "      <td>0.004595</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.107580</td>\n",
       "      <td>0.016929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.079651</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>0.642203</td>\n",
       "      <td>0.783669</td>\n",
       "      <td>mse</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.632470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452446</td>\n",
       "      <td>0.807411</td>\n",
       "      <td>0.661534</td>\n",
       "      <td>0.761985</td>\n",
       "      <td>0.677862</td>\n",
       "      <td>0.795574</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.109303</td>\n",
       "      <td>0.016629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.156604</td>\n",
       "      <td>0.008930</td>\n",
       "      <td>0.645046</td>\n",
       "      <td>0.783199</td>\n",
       "      <td>mse</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>13</td>\n",
       "      <td>0.646579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453979</td>\n",
       "      <td>0.809105</td>\n",
       "      <td>0.664311</td>\n",
       "      <td>0.762408</td>\n",
       "      <td>0.674158</td>\n",
       "      <td>0.792468</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.108315</td>\n",
       "      <td>0.016699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.042447</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>0.772805</td>\n",
       "      <td>0.966819</td>\n",
       "      <td>mse</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'n_estima...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.779761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534255</td>\n",
       "      <td>0.973722</td>\n",
       "      <td>0.834329</td>\n",
       "      <td>0.969750</td>\n",
       "      <td>0.826922</td>\n",
       "      <td>0.963078</td>\n",
       "      <td>0.001884</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.125263</td>\n",
       "      <td>0.004298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.082083</td>\n",
       "      <td>0.004693</td>\n",
       "      <td>0.779033</td>\n",
       "      <td>0.967569</td>\n",
       "      <td>mse</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'n_estima...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.771612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537566</td>\n",
       "      <td>0.973433</td>\n",
       "      <td>0.843001</td>\n",
       "      <td>0.968763</td>\n",
       "      <td>0.847150</td>\n",
       "      <td>0.964772</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.128224</td>\n",
       "      <td>0.003374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.047817         0.003355         0.635309          0.778977   \n",
       "1       0.079651         0.004593         0.642203          0.783669   \n",
       "2       0.156604         0.008930         0.645046          0.783199   \n",
       "3       0.042447         0.002823         0.772805          0.966819   \n",
       "4       0.082083         0.004693         0.779033          0.967569   \n",
       "\n",
       "  param_criterion param_max_depth param_n_estimators  \\\n",
       "0             mse               2                 50   \n",
       "1             mse               2                100   \n",
       "2             mse               2                200   \n",
       "3             mse               6                 50   \n",
       "4             mse               6                100   \n",
       "\n",
       "                                              params  rank_test_score  \\\n",
       "0  {'criterion': 'mse', 'max_depth': 2, 'n_estima...               15   \n",
       "1  {'criterion': 'mse', 'max_depth': 2, 'n_estima...               14   \n",
       "2  {'criterion': 'mse', 'max_depth': 2, 'n_estima...               13   \n",
       "3  {'criterion': 'mse', 'max_depth': 6, 'n_estima...                6   \n",
       "4  {'criterion': 'mse', 'max_depth': 6, 'n_estima...                3   \n",
       "\n",
       "   split0_test_score       ...         split2_test_score  split2_train_score  \\\n",
       "0           0.613964       ...                  0.451744            0.804077   \n",
       "1           0.632470       ...                  0.452446            0.807411   \n",
       "2           0.646579       ...                  0.453979            0.809105   \n",
       "3           0.779761       ...                  0.534255            0.973722   \n",
       "4           0.771612       ...                  0.537566            0.973433   \n",
       "\n",
       "   split3_test_score  split3_train_score  split4_test_score  \\\n",
       "0           0.656762            0.758853           0.675603   \n",
       "1           0.661534            0.761985           0.677862   \n",
       "2           0.664311            0.762408           0.674158   \n",
       "3           0.834329            0.969750           0.826922   \n",
       "4           0.843001            0.968763           0.847150   \n",
       "\n",
       "   split4_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0            0.792493      0.004595        0.000730        0.107580   \n",
       "1            0.795574      0.003166        0.000032        0.109303   \n",
       "2            0.792468      0.003978        0.000223        0.108315   \n",
       "3            0.963078      0.001884        0.000285        0.125263   \n",
       "4            0.964772      0.002411        0.000024        0.128224   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.016929  \n",
       "1         0.016629  \n",
       "2         0.016699  \n",
       "3         0.004298  \n",
       "4         0.003374  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=grid_cv_regr.cv_results_)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6875"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_clf.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here hyperparameterization did not improve!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
