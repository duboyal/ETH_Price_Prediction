{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELING: Exploring the random forest regressor and classifier to predict price\n",
    "first we read in the data, and also make the classifier target list 'rise_lower' from our existing data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ultra_mega_frame = pd.read_csv('../1)DATA/df_ultra_mega_frame2.csv')\n",
    "df_ultra_mega_frame['date'] = pd.to_datetime(df_ultra_mega_frame['date'],infer_datetime_format=True)\n",
    "df_ultra_mega_frame.index = df_ultra_mega_frame['date']\n",
    "#df_ultra_mega_classifier = df_ultra_mega_frame #starting here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ultra_mega_frame['neg_count'] = df_ultra_mega_frame['neg_count']*(-1)\n",
    "df_ultra_mega_frame['neg_count'] = df_ultra_mega_frame['neg_count'] - df_ultra_mega_frame['neg_count'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ultra_mega_frame['neg_count'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ultra_mega_frame['count'] = df_ultra_mega_frame['neg_count'] + df_ultra_mega_frame['pos_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>SearchFrequency</th>\n",
       "      <th>DJI</th>\n",
       "      <th>price_btc</th>\n",
       "      <th>price_eth</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>pos_count</th>\n",
       "      <th>neg_count</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-16</th>\n",
       "      <td>2017-11-16</td>\n",
       "      <td>55</td>\n",
       "      <td>23458.359375</td>\n",
       "      <td>7871.69</td>\n",
       "      <td>330.92</td>\n",
       "      <td>0.089579</td>\n",
       "      <td>14</td>\n",
       "      <td>75</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-17</th>\n",
       "      <td>2017-11-17</td>\n",
       "      <td>75</td>\n",
       "      <td>23358.240234</td>\n",
       "      <td>7708.99</td>\n",
       "      <td>332.39</td>\n",
       "      <td>0.087821</td>\n",
       "      <td>8</td>\n",
       "      <td>59</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-18</th>\n",
       "      <td>2017-11-18</td>\n",
       "      <td>103</td>\n",
       "      <td>23358.240234</td>\n",
       "      <td>7790.15</td>\n",
       "      <td>347.61</td>\n",
       "      <td>0.092867</td>\n",
       "      <td>5</td>\n",
       "      <td>82</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-19</th>\n",
       "      <td>2017-11-19</td>\n",
       "      <td>65</td>\n",
       "      <td>23358.240234</td>\n",
       "      <td>8036.49</td>\n",
       "      <td>354.39</td>\n",
       "      <td>0.092423</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20</th>\n",
       "      <td>2017-11-20</td>\n",
       "      <td>96</td>\n",
       "      <td>23430.330078</td>\n",
       "      <td>8200.64</td>\n",
       "      <td>366.73</td>\n",
       "      <td>0.093611</td>\n",
       "      <td>7</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  SearchFrequency           DJI  price_btc  price_eth  \\\n",
       "date                                                                         \n",
       "2017-11-16 2017-11-16               55  23458.359375    7871.69     330.92   \n",
       "2017-11-17 2017-11-17               75  23358.240234    7708.99     332.39   \n",
       "2017-11-18 2017-11-18              103  23358.240234    7790.15     347.61   \n",
       "2017-11-19 2017-11-19               65  23358.240234    8036.49     354.39   \n",
       "2017-11-20 2017-11-20               96  23430.330078    8200.64     366.73   \n",
       "\n",
       "            sentiment  pos_count  neg_count  count  \n",
       "date                                                \n",
       "2017-11-16   0.089579         14         75     89  \n",
       "2017-11-17   0.087821          8         59     67  \n",
       "2017-11-18   0.092867          5         82     87  \n",
       "2017-11-19   0.092423          3         78     81  \n",
       "2017-11-20   0.093611          7         80     87  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ultra_mega_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we create 'rise_fall_list' for ethereum that will be inserted back into the dataframe to be used as a feature in the classifier model. We later do this for the other selected features as well. The features we selected were Bitcoin price, Dow Jones Index and google search frequency. Sentiment was included originally but it was deemed to return an \"importance value\" too close to zero to be considered more useful than unuseful to the model due to the curse of dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "price_list = df_ultra_mega_frame['price_eth']\n",
    "rise_fall_list = []\n",
    "\n",
    "for index, item in enumerate(df_ultra_mega_frame['price_eth']):\n",
    "    if df_ultra_mega_frame['price_eth'].iloc[index-1] < df_ultra_mega_frame['price_eth'].iloc[index]:\n",
    "        rise_fall_list.append(1)\n",
    "    else:\n",
    "        rise_fall_list.append(0)\n",
    "        \n",
    "df_ultra_mega_frame['rise_lower'] = rise_fall_list\n",
    "#df_ultra_mega_classifier = df_ultra_mega_classifier['2017-11-17':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor \n",
    "Here below we convert our y (being the target variable or label by formalism) to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array(df_ultra_mega_frame['price_eth'])\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= df_ultra_mega_frame.drop(['price_eth','date','rise_lower'], axis = 1) #'pos_count','neg_count' \n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns) #this way we remeber the column names\n",
    "# Convert to numpy array\n",
    "X = np.array(features) #because once we convert to np array it drops the names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point it's a good moment to to check X.shape and y.shape to make sure our y array is one dimensional and our X array is an 'nd array' with n corresponding to the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X.shape\n",
    "#y.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform our test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here we instantiate our Random Forest regressor. We first pick max_depth=2 and random_state=0 to begin with and then we later perform a Cv grid search to optimize the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "regr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we print out our feature importancce values to give us an idea of which feature is the most important to our model. Here we note that any features that go to zero would be considered to not play any role in improving our model. There are two features that are close to zero but still non-zero, so they technically are still marginally improving our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SearchFrequency</th>\n",
       "      <th>DJI</th>\n",
       "      <th>price_btc</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>pos_count</th>\n",
       "      <th>neg_count</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-16</th>\n",
       "      <td>55</td>\n",
       "      <td>23458.359375</td>\n",
       "      <td>7871.69</td>\n",
       "      <td>0.089579</td>\n",
       "      <td>14</td>\n",
       "      <td>75</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-17</th>\n",
       "      <td>75</td>\n",
       "      <td>23358.240234</td>\n",
       "      <td>7708.99</td>\n",
       "      <td>0.087821</td>\n",
       "      <td>8</td>\n",
       "      <td>59</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-18</th>\n",
       "      <td>103</td>\n",
       "      <td>23358.240234</td>\n",
       "      <td>7790.15</td>\n",
       "      <td>0.092867</td>\n",
       "      <td>5</td>\n",
       "      <td>82</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-19</th>\n",
       "      <td>65</td>\n",
       "      <td>23358.240234</td>\n",
       "      <td>8036.49</td>\n",
       "      <td>0.092423</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20</th>\n",
       "      <td>96</td>\n",
       "      <td>23430.330078</td>\n",
       "      <td>8200.64</td>\n",
       "      <td>0.093611</td>\n",
       "      <td>7</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            SearchFrequency           DJI  price_btc  sentiment  pos_count  \\\n",
       "date                                                                         \n",
       "2017-11-16               55  23458.359375    7871.69   0.089579         14   \n",
       "2017-11-17               75  23358.240234    7708.99   0.087821          8   \n",
       "2017-11-18              103  23358.240234    7790.15   0.092867          5   \n",
       "2017-11-19               65  23358.240234    8036.49   0.092423          3   \n",
       "2017-11-20               96  23430.330078    8200.64   0.093611          7   \n",
       "\n",
       "            neg_count  count  \n",
       "date                          \n",
       "2017-11-16         75     89  \n",
       "2017-11-17         59     67  \n",
       "2017-11-18         82     87  \n",
       "2017-11-19         78     81  \n",
       "2017-11-20         80     87  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01590281 0.93784831 0.03763274 0.00459188 0.00402426 0.\n",
      " 0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(regr.feature_importances_) #strength of importance of feature in the model\n",
    "#but is using the other two because they are not zero!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above numbers signify the following features respectivley\n",
    "\n",
    "1)  search frequency\n",
    "2)  Dow Jones Index\n",
    "3)  Bitcoin Price \n",
    "4)  sentiment\n",
    "5)  count of positive n-gram\n",
    "\n",
    "6)  count of negative n gram (effective net by first multiplying the vector by a negative 1 then substracting its minimum)\n",
    "\n",
    "7)  the addition of the last two\n",
    "\n",
    "We originally had input a feature column of the polarity score of Ethereum sentiment for each day (all reddit data that was scraped) and then another as well a feature called pos_count and  feature went to zero so we chose not to include it in our model.\n",
    "\n",
    "when you have more features, you are basically saying you need more data to adequetly sample the space or else you run into the curse of dimensionality. This is what tells you that for the more dimenions you have, you need more data in total in order to sample your entire space. What do you run the risk of otherwise? of being innaccurate. in which way? in the way that your data set you have doesnt adequatley cover sample space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1114.12674763  615.17481678  845.8458259  1087.26301234  845.8458259\n",
      " 1087.26301234  770.27835392  928.40434538  824.74849407  770.27835392\n",
      "  450.14618843  824.74849407  770.27835392  770.27835392  931.99236558\n",
      "  598.42484535  876.61368701  450.14618843  983.78302396  466.89615986\n",
      "  770.27835392  748.29913732 1087.26301234  430.93393129  983.78302396\n",
      "  770.27835392 1087.26301234  483.66188623  770.27835392  770.27835392\n",
      "  770.27835392  638.64628106]\n"
     ]
    }
   ],
   "source": [
    "print(regr.predict(X_test)) #predict y given x test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above: X_test is the argument taken in, but the output for the predict function is only one dimension just like y. We can later graph this result from predict against Y test to explicitly see if our model worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8038670793562294"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now can compare with the original X and Y_train!!!\n",
    "#using score \n",
    "regr.score(X_test, Y_test) #X_test , as seen above...X_test has more dimensions than the output on predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This score returns an r squared value. It is a percentage, how well the variablity of your data is captured by a given model comparisons betweeen different models scores tells you which model is better.\n",
    "\n",
    "below we perform a CV grid search across the following parameters: \"criterion\": [\"mse\", \"mae\"], \"max_depth\": [2, 6, 8], \"n_estimators\":[50, 100, 200], and we optimize our score based off of the grid search. We also see that we perporm a cross validation of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
       "           verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'criterion': ['mse', 'mae'], 'max_depth': [2, 6, 8], 'n_estimators': [50, 100, 200]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use a grid search\n",
    "param_grid = {\"criterion\": [\"mse\", \"mae\"], #mean squared error and mean absolute error in documentation\n",
    "              #\"min_samples_split\": [10, 20, 40],\n",
    "              \"max_depth\": [2, 6, 8],\n",
    "              \"n_estimators\":[50, 100, 200]\n",
    "              #\"min_samples_leaf\": [20, 40, 100],\n",
    "              #\"max_leaf_nodes\": [5, 20, 100, 500, 800],\n",
    "              }\n",
    "\n",
    "grid_cv_regr = GridSearchCV(regr, param_grid, cv=5)\n",
    "\n",
    "grid_cv_regr.fit(X_train, Y_train) #features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Squared::0.7366751155318549\n",
      "Best Hyperparameters::\n",
      "{'criterion': 'mse', 'max_depth': 8, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "print(\"R-Squared::{}\".format(grid_cv_regr.best_score_))\n",
    "print(\"Best Hyperparameters::\\n{}\".format(grid_cv_regr.best_params_))\n",
    "\n",
    "#random forest builds multiple decision trees \n",
    "#best number of decision trees\n",
    "#depth of each tree shouldnt be more than 8 levels\n",
    "#go down to 8 levels(splits) but dont split it further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How is it that after the hyperparameter tuning, our R squared went down? difference between rsquared is that this one tells how well did this model work for hyperparametrization on the train data, because we dont give it the test data. You don't want any part of you model to be trained on the test data. So this part is NOT the same R squared from our score output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051947</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>0.619308</td>\n",
       "      <td>0.787531</td>\n",
       "      <td>mse</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.623562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.445171</td>\n",
       "      <td>0.811491</td>\n",
       "      <td>0.651783</td>\n",
       "      <td>0.766787</td>\n",
       "      <td>0.678517</td>\n",
       "      <td>0.796836</td>\n",
       "      <td>0.008925</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.091400</td>\n",
       "      <td>0.015349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.081719</td>\n",
       "      <td>0.004901</td>\n",
       "      <td>0.621898</td>\n",
       "      <td>0.790982</td>\n",
       "      <td>mse</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.633859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452479</td>\n",
       "      <td>0.811443</td>\n",
       "      <td>0.656320</td>\n",
       "      <td>0.769239</td>\n",
       "      <td>0.671960</td>\n",
       "      <td>0.800334</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.087781</td>\n",
       "      <td>0.014223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.171809</td>\n",
       "      <td>0.008545</td>\n",
       "      <td>0.630687</td>\n",
       "      <td>0.791223</td>\n",
       "      <td>mse</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>13</td>\n",
       "      <td>0.653439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.462606</td>\n",
       "      <td>0.813729</td>\n",
       "      <td>0.655571</td>\n",
       "      <td>0.772877</td>\n",
       "      <td>0.668467</td>\n",
       "      <td>0.797499</td>\n",
       "      <td>0.014097</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.087533</td>\n",
       "      <td>0.013693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.044912</td>\n",
       "      <td>0.002565</td>\n",
       "      <td>0.728748</td>\n",
       "      <td>0.960129</td>\n",
       "      <td>mse</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'n_estima...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.831639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484078</td>\n",
       "      <td>0.965610</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.960208</td>\n",
       "      <td>0.715600</td>\n",
       "      <td>0.959796</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.129490</td>\n",
       "      <td>0.003040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.088961</td>\n",
       "      <td>0.004703</td>\n",
       "      <td>0.732487</td>\n",
       "      <td>0.960131</td>\n",
       "      <td>mse</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'n_estima...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.802100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486381</td>\n",
       "      <td>0.967706</td>\n",
       "      <td>0.814809</td>\n",
       "      <td>0.958623</td>\n",
       "      <td>0.746659</td>\n",
       "      <td>0.956543</td>\n",
       "      <td>0.002450</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.126286</td>\n",
       "      <td>0.003935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.051947         0.003490         0.619308          0.787531   \n",
       "1       0.081719         0.004901         0.621898          0.790982   \n",
       "2       0.171809         0.008545         0.630687          0.791223   \n",
       "3       0.044912         0.002565         0.728748          0.960129   \n",
       "4       0.088961         0.004703         0.732487          0.960131   \n",
       "\n",
       "  param_criterion param_max_depth param_n_estimators  \\\n",
       "0             mse               2                 50   \n",
       "1             mse               2                100   \n",
       "2             mse               2                200   \n",
       "3             mse               6                 50   \n",
       "4             mse               6                100   \n",
       "\n",
       "                                              params  rank_test_score  \\\n",
       "0  {'criterion': 'mse', 'max_depth': 2, 'n_estima...               15   \n",
       "1  {'criterion': 'mse', 'max_depth': 2, 'n_estima...               14   \n",
       "2  {'criterion': 'mse', 'max_depth': 2, 'n_estima...               13   \n",
       "3  {'criterion': 'mse', 'max_depth': 6, 'n_estima...                6   \n",
       "4  {'criterion': 'mse', 'max_depth': 6, 'n_estima...                3   \n",
       "\n",
       "   split0_test_score       ...         split2_test_score  split2_train_score  \\\n",
       "0           0.623562       ...                  0.445171            0.811491   \n",
       "1           0.633859       ...                  0.452479            0.811443   \n",
       "2           0.653439       ...                  0.462606            0.813729   \n",
       "3           0.831639       ...                  0.484078            0.965610   \n",
       "4           0.802100       ...                  0.486381            0.967706   \n",
       "\n",
       "   split3_test_score  split3_train_score  split4_test_score  \\\n",
       "0           0.651783            0.766787           0.678517   \n",
       "1           0.656320            0.769239           0.671960   \n",
       "2           0.655571            0.772877           0.668467   \n",
       "3           0.820833            0.960208           0.715600   \n",
       "4           0.814809            0.958623           0.746659   \n",
       "\n",
       "   split4_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0            0.796836      0.008925        0.001079        0.091400   \n",
       "1            0.800334      0.001754        0.000998        0.087781   \n",
       "2            0.797499      0.014097        0.000185        0.087533   \n",
       "3            0.959796      0.002269        0.000116        0.129490   \n",
       "4            0.956543      0.002450        0.000206        0.126286   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.015349  \n",
       "1         0.014223  \n",
       "2         0.013693  \n",
       "3         0.003040  \n",
       "4         0.003935  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=grid_cv_regr.cv_results_)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'mse', 'max_depth': 2, 'n_estimators': 50} 0.6193 0.0914\n",
      "{'criterion': 'mse', 'max_depth': 2, 'n_estimators': 100} 0.6219 0.0878\n",
      "{'criterion': 'mse', 'max_depth': 2, 'n_estimators': 200} 0.6307 0.0875\n",
      "{'criterion': 'mse', 'max_depth': 6, 'n_estimators': 50} 0.7287 0.1295\n",
      "{'criterion': 'mse', 'max_depth': 6, 'n_estimators': 100} 0.7325 0.1263\n",
      "{'criterion': 'mse', 'max_depth': 6, 'n_estimators': 200} 0.7353 0.1281\n",
      "{'criterion': 'mse', 'max_depth': 8, 'n_estimators': 50} 0.7324 0.1274\n",
      "{'criterion': 'mse', 'max_depth': 8, 'n_estimators': 100} 0.7324 0.1265\n",
      "{'criterion': 'mse', 'max_depth': 8, 'n_estimators': 200} 0.7367 0.1273\n",
      "{'criterion': 'mae', 'max_depth': 2, 'n_estimators': 50} 0.5699 0.1262\n",
      "{'criterion': 'mae', 'max_depth': 2, 'n_estimators': 100} 0.5937 0.1287\n",
      "{'criterion': 'mae', 'max_depth': 2, 'n_estimators': 200} 0.5983 0.1405\n",
      "{'criterion': 'mae', 'max_depth': 6, 'n_estimators': 50} 0.6998 0.1691\n",
      "{'criterion': 'mae', 'max_depth': 6, 'n_estimators': 100} 0.7132 0.1678\n",
      "{'criterion': 'mae', 'max_depth': 6, 'n_estimators': 200} 0.7158 0.1732\n",
      "{'criterion': 'mae', 'max_depth': 8, 'n_estimators': 50} 0.6999 0.1766\n",
      "{'criterion': 'mae', 'max_depth': 8, 'n_estimators': 100} 0.7154 0.1722\n",
      "{'criterion': 'mae', 'max_depth': 8, 'n_estimators': 200} 0.7194 0.1749\n"
     ]
    }
   ],
   "source": [
    "results = grid_cv_regr.cv_results_\n",
    "for param, score_mean, score_sd in zip(results['params'], results['mean_test_score'], results['std_test_score']):\n",
    "    print(param, round(score_mean, 4), round(score_sd, 4))\n",
    "    \n",
    "#the highest is n=100, and mx depth 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9245428491244888"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_regr.score(X_test, Y_test) #this is really great!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a good score! since the feature of 'sentiment' was so close to zero, lets see if removing the feasture improves the accuracy of the model! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now compare to dropping features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array(df_ultra_mega_frame['price_eth'])\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= df_ultra_mega_frame.drop(['price_eth','date','rise_lower','sentiment','pos_count', 'neg_count',\n",
    "       'count'], axis = 1)\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns) #this way we remeber the column names\n",
    "# Convert to numpy array\n",
    "X = np.array(features) #because once we convert to np array it drops the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "regr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01590281 0.94405113 0.04004606]\n"
     ]
    }
   ],
   "source": [
    "print(regr.feature_importances_) #strength of importance of feature in the model\n",
    "#but is using the other two because they are not zero!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1114.12674763  617.89886313  845.8458259  1087.26301234  845.8458259\n",
      " 1087.26301234  770.27835392  928.40434538  824.74849407  770.27835392\n",
      "  438.05447288  824.74849407  770.27835392  770.27835392  931.99236558\n",
      "  617.89886313  876.61368701  451.59475065  983.78302396  451.59475065\n",
      "  770.27835392  748.29913732 1087.26301234  418.84221573  983.78302396\n",
      "  770.27835392 1087.26301234  503.13590401  770.27835392  770.27835392\n",
      "  770.27835392  641.37032741]\n"
     ]
    }
   ],
   "source": [
    "print(regr.predict(X_test)) #predict y given x test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8017445780922451"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now can compare with the original X_train!!!\n",
    "#using score \n",
    "regr.score(X_test, Y_test) #X_test , as seen above...X_test has more dimensions than the output on predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
       "           verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'criterion': ['mse', 'mae'], 'max_depth': [2, 6, 8], 'n_estimators': [50, 100, 200]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use a grid search\n",
    "param_grid = {\"criterion\": [\"mse\", \"mae\"], #mean squared error and mean absolute error in documentation\n",
    "              #\"min_samples_split\": [10, 20, 40],\n",
    "              \"max_depth\": [2, 6, 8],\n",
    "              \"n_estimators\":[50, 100, 200]\n",
    "              #\"min_samples_leaf\": [20, 40, 100],\n",
    "              #\"max_leaf_nodes\": [5, 20, 100, 500, 800],\n",
    "              }\n",
    "\n",
    "grid_cv_regr = GridSearchCV(regr, param_grid, cv=5)\n",
    "\n",
    "grid_cv_regr.fit(X_train, Y_train) #features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1128.501875  ,  512.14903   ,  832.76701111, 1050.22647357,\n",
       "        925.00969111, 1028.64646167,  715.78464003, 1066.31553952,\n",
       "        767.53275903,  749.61424075,  415.5053    ,  902.84316188,\n",
       "        780.90016533,  791.78052726,  933.56418   ,  484.02071929,\n",
       "        965.39498778,  470.2634    , 1169.45010952,  461.18355   ,\n",
       "        764.58507802,  725.66559992, 1047.346585  ,  416.2924    ,\n",
       "       1184.74674286,  751.40751671, 1041.08642214,  453.87266667,\n",
       "        829.65888079,  656.20527978,  771.78909282,  505.47520595])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_regr.predict(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the output and notice that its one dimensional which is what we want. We now set this variable to Y_predicted so that we can later graph it against Y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_predicted = grid_cv_regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Squared::0.781573998077793\n",
      "Best Hyperparameters::\n",
      "{'criterion': 'mse', 'max_depth': 8, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(\"R-Squared::{}\".format(grid_cv_regr.best_score_))\n",
    "print(\"Best Hyperparameters::\\n{}\".format(grid_cv_regr.best_params_))\n",
    "\n",
    "#random forest builds multiple decision trees \n",
    "#best number of decision trees\n",
    "#depth of each tree shouldnt be more than 8 levels\n",
    "#go down to 8 levels(splits) but dont split it further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.055080</td>\n",
       "      <td>0.002569</td>\n",
       "      <td>0.635309</td>\n",
       "      <td>0.778977</td>\n",
       "      <td>mse</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.613964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451744</td>\n",
       "      <td>0.804077</td>\n",
       "      <td>0.656762</td>\n",
       "      <td>0.758853</td>\n",
       "      <td>0.675603</td>\n",
       "      <td>0.792493</td>\n",
       "      <td>0.014472</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.107580</td>\n",
       "      <td>0.016929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.090670</td>\n",
       "      <td>0.005130</td>\n",
       "      <td>0.642203</td>\n",
       "      <td>0.783669</td>\n",
       "      <td>mse</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.632470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452446</td>\n",
       "      <td>0.807411</td>\n",
       "      <td>0.661534</td>\n",
       "      <td>0.761985</td>\n",
       "      <td>0.677862</td>\n",
       "      <td>0.795574</td>\n",
       "      <td>0.013662</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.109303</td>\n",
       "      <td>0.016629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.165446</td>\n",
       "      <td>0.009154</td>\n",
       "      <td>0.645046</td>\n",
       "      <td>0.783199</td>\n",
       "      <td>mse</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>13</td>\n",
       "      <td>0.646579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453979</td>\n",
       "      <td>0.809105</td>\n",
       "      <td>0.664311</td>\n",
       "      <td>0.762408</td>\n",
       "      <td>0.674158</td>\n",
       "      <td>0.792468</td>\n",
       "      <td>0.006488</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.108315</td>\n",
       "      <td>0.016699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.050730</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>0.772805</td>\n",
       "      <td>0.966819</td>\n",
       "      <td>mse</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'n_estima...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.779761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534255</td>\n",
       "      <td>0.973722</td>\n",
       "      <td>0.834329</td>\n",
       "      <td>0.969750</td>\n",
       "      <td>0.826922</td>\n",
       "      <td>0.963078</td>\n",
       "      <td>0.009542</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.125263</td>\n",
       "      <td>0.004298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.089234</td>\n",
       "      <td>0.005778</td>\n",
       "      <td>0.779033</td>\n",
       "      <td>0.967569</td>\n",
       "      <td>mse</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'n_estima...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.771612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537566</td>\n",
       "      <td>0.973433</td>\n",
       "      <td>0.843001</td>\n",
       "      <td>0.968763</td>\n",
       "      <td>0.847150</td>\n",
       "      <td>0.964772</td>\n",
       "      <td>0.008009</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.128224</td>\n",
       "      <td>0.003374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.055080         0.002569         0.635309          0.778977   \n",
       "1       0.090670         0.005130         0.642203          0.783669   \n",
       "2       0.165446         0.009154         0.645046          0.783199   \n",
       "3       0.050730         0.003537         0.772805          0.966819   \n",
       "4       0.089234         0.005778         0.779033          0.967569   \n",
       "\n",
       "  param_criterion param_max_depth param_n_estimators  \\\n",
       "0             mse               2                 50   \n",
       "1             mse               2                100   \n",
       "2             mse               2                200   \n",
       "3             mse               6                 50   \n",
       "4             mse               6                100   \n",
       "\n",
       "                                              params  rank_test_score  \\\n",
       "0  {'criterion': 'mse', 'max_depth': 2, 'n_estima...               15   \n",
       "1  {'criterion': 'mse', 'max_depth': 2, 'n_estima...               14   \n",
       "2  {'criterion': 'mse', 'max_depth': 2, 'n_estima...               13   \n",
       "3  {'criterion': 'mse', 'max_depth': 6, 'n_estima...                6   \n",
       "4  {'criterion': 'mse', 'max_depth': 6, 'n_estima...                3   \n",
       "\n",
       "   split0_test_score       ...         split2_test_score  split2_train_score  \\\n",
       "0           0.613964       ...                  0.451744            0.804077   \n",
       "1           0.632470       ...                  0.452446            0.807411   \n",
       "2           0.646579       ...                  0.453979            0.809105   \n",
       "3           0.779761       ...                  0.534255            0.973722   \n",
       "4           0.771612       ...                  0.537566            0.973433   \n",
       "\n",
       "   split3_test_score  split3_train_score  split4_test_score  \\\n",
       "0           0.656762            0.758853           0.675603   \n",
       "1           0.661534            0.761985           0.677862   \n",
       "2           0.664311            0.762408           0.674158   \n",
       "3           0.834329            0.969750           0.826922   \n",
       "4           0.843001            0.968763           0.847150   \n",
       "\n",
       "   split4_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0            0.792493      0.014472        0.000094        0.107580   \n",
       "1            0.795574      0.013662        0.000679        0.109303   \n",
       "2            0.792468      0.006488        0.000613        0.108315   \n",
       "3            0.963078      0.009542        0.001993        0.125263   \n",
       "4            0.964772      0.008009        0.001522        0.128224   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.016929  \n",
       "1         0.016629  \n",
       "2         0.016699  \n",
       "3         0.004298  \n",
       "4         0.003374  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=grid_cv_regr.cv_results_)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'mse', 'max_depth': 2, 'n_estimators': 50} 0.6353 0.1076\n",
      "{'criterion': 'mse', 'max_depth': 2, 'n_estimators': 100} 0.6422 0.1093\n",
      "{'criterion': 'mse', 'max_depth': 2, 'n_estimators': 200} 0.645 0.1083\n",
      "{'criterion': 'mse', 'max_depth': 6, 'n_estimators': 50} 0.7728 0.1253\n",
      "{'criterion': 'mse', 'max_depth': 6, 'n_estimators': 100} 0.779 0.1282\n",
      "{'criterion': 'mse', 'max_depth': 6, 'n_estimators': 200} 0.7762 0.1262\n",
      "{'criterion': 'mse', 'max_depth': 8, 'n_estimators': 50} 0.7741 0.1249\n",
      "{'criterion': 'mse', 'max_depth': 8, 'n_estimators': 100} 0.7816 0.1313\n",
      "{'criterion': 'mse', 'max_depth': 8, 'n_estimators': 200} 0.7797 0.1288\n",
      "{'criterion': 'mae', 'max_depth': 2, 'n_estimators': 50} 0.589 0.1577\n",
      "{'criterion': 'mae', 'max_depth': 2, 'n_estimators': 100} 0.6003 0.16\n",
      "{'criterion': 'mae', 'max_depth': 2, 'n_estimators': 200} 0.6018 0.1695\n",
      "{'criterion': 'mae', 'max_depth': 6, 'n_estimators': 50} 0.739 0.1527\n",
      "{'criterion': 'mae', 'max_depth': 6, 'n_estimators': 100} 0.74 0.1553\n",
      "{'criterion': 'mae', 'max_depth': 6, 'n_estimators': 200} 0.7376 0.1603\n",
      "{'criterion': 'mae', 'max_depth': 8, 'n_estimators': 50} 0.7405 0.1567\n",
      "{'criterion': 'mae', 'max_depth': 8, 'n_estimators': 100} 0.7454 0.1541\n",
      "{'criterion': 'mae', 'max_depth': 8, 'n_estimators': 200} 0.7421 0.1601\n"
     ]
    }
   ],
   "source": [
    "results = grid_cv_regr.cv_results_\n",
    "for param, score_mean, score_sd in zip(results['params'], results['mean_test_score'], results['std_test_score']):\n",
    "    print(param, round(score_mean, 4), round(score_sd, 4))\n",
    "    \n",
    "#the highest is n=100, and mx depth 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9439053866082423"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_regr.score(X_test, Y_test) #this is really great!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we see that hyperparameterization worked!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAFuCAYAAAA4QJSOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkMBNCCGEEKJH/H/Fvorgim3fOAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(Y_test, alpha = 1)\n",
    "plt.plot(Y_predicted, alpha = 1)\n",
    "\n",
    "# need to add legend\n",
    "plt.ylabel('normalized scale')\n",
    "plt.xticks(rotation=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid_cv_regr.score(X_test, Y_test), performs the same thing, (notice the number is the same) it runs the model again with the optimized parameters\n",
    "\n",
    "Note: this doesn't forcast what is to come. This model tells us How changes in the Dow Jones (and other features) might cause changes in ethereum. If you can use Time series analysis to forecast changes in the dow jones, you might be able to predict changes in ethereum, but you dont have the ability to do forecasting with this model.\n",
    "\n",
    "Can A Regression model forecast? The most you can forcast Is If you predicted dow jones values and fed that prediction into a model to forcast ethereum price. Dow jones index has a lot of historical data backing it up as opposed to etheruem, so thats why it could posible be used as an exogeneous variable in a time series model (ARIMAX was looked into breifly for this prroject and more will be included on that.\n",
    "\n",
    "A classification model can be put into place in order to predict if the price of ethereum will go up or down. In order to do this all of the features that are deemed significant must also be converted to a binary list of 0's or 1's. A 0 signifying that the price dropped since the day before and a 1 signifying that the price rose since then.\n",
    "\n",
    "We will now look at classification and for this we weill drop the sentiment feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now for classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df_ultra_mega_frame['rise_lower']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array(df_ultra_mega_frame['rise_lower'])\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= df_ultra_mega_frame.drop(['date','rise_lower','price_eth','sentiment'], axis = 1)\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns) #this way we remeber the column names\n",
    "# Convert to numpy array\n",
    "X = np.array(features) #because once we convert to np array it drops the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#features #toggle this to double check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06095095, 0.29641318, 0.29611777, 0.        , 0.11169043,\n",
       "       0.23482766])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [2, 6, 8], 'n_estimators': [50, 100, 200]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use a grid search\n",
    "\n",
    "param_grid = {#\"criterion\": [\"mse\", \"mae\"], #mean squared error and mean absolute error in documentation\n",
    "              #\"min_samples_split\": [10, 20, 40],\n",
    "              \"max_depth\": [2, 6, 8],\n",
    "              \"n_estimators\":[50, 100, 200]\n",
    "              #\"min_samples_leaf\": [20, 40, 100],\n",
    "              #\"max_leaf_nodes\": [5, 20, 100, 500, 800],\n",
    "              }\n",
    "\n",
    "grid_cv_clf = GridSearchCV(clf, param_grid, cv=5)\n",
    "grid_cv_clf.fit(X_train, Y_train) #features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Squared::0.781573998077793\n",
      "Best Hyperparameters::\n",
      "{'criterion': 'mse', 'max_depth': 8, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(\"R-Squared::{}\".format(grid_cv_regr.best_score_))\n",
    "print(\"Best Hyperparameters::\\n{}\".format(grid_cv_regr.best_params_))\n",
    "\n",
    "#random forest builds multiple decision trees \n",
    "#best number of decision trees\n",
    "#depth of each tree shouldnt be more than 8 levels\n",
    "#go down to 8 levels(splits) but dont split it further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.047817</td>\n",
       "      <td>0.003355</td>\n",
       "      <td>0.635309</td>\n",
       "      <td>0.778977</td>\n",
       "      <td>mse</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.613964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451744</td>\n",
       "      <td>0.804077</td>\n",
       "      <td>0.656762</td>\n",
       "      <td>0.758853</td>\n",
       "      <td>0.675603</td>\n",
       "      <td>0.792493</td>\n",
       "      <td>0.004595</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.107580</td>\n",
       "      <td>0.016929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.079651</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>0.642203</td>\n",
       "      <td>0.783669</td>\n",
       "      <td>mse</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.632470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452446</td>\n",
       "      <td>0.807411</td>\n",
       "      <td>0.661534</td>\n",
       "      <td>0.761985</td>\n",
       "      <td>0.677862</td>\n",
       "      <td>0.795574</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.109303</td>\n",
       "      <td>0.016629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.156604</td>\n",
       "      <td>0.008930</td>\n",
       "      <td>0.645046</td>\n",
       "      <td>0.783199</td>\n",
       "      <td>mse</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>13</td>\n",
       "      <td>0.646579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453979</td>\n",
       "      <td>0.809105</td>\n",
       "      <td>0.664311</td>\n",
       "      <td>0.762408</td>\n",
       "      <td>0.674158</td>\n",
       "      <td>0.792468</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.108315</td>\n",
       "      <td>0.016699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.042447</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>0.772805</td>\n",
       "      <td>0.966819</td>\n",
       "      <td>mse</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'n_estima...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.779761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534255</td>\n",
       "      <td>0.973722</td>\n",
       "      <td>0.834329</td>\n",
       "      <td>0.969750</td>\n",
       "      <td>0.826922</td>\n",
       "      <td>0.963078</td>\n",
       "      <td>0.001884</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.125263</td>\n",
       "      <td>0.004298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.082083</td>\n",
       "      <td>0.004693</td>\n",
       "      <td>0.779033</td>\n",
       "      <td>0.967569</td>\n",
       "      <td>mse</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'n_estima...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.771612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537566</td>\n",
       "      <td>0.973433</td>\n",
       "      <td>0.843001</td>\n",
       "      <td>0.968763</td>\n",
       "      <td>0.847150</td>\n",
       "      <td>0.964772</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.128224</td>\n",
       "      <td>0.003374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.047817         0.003355         0.635309          0.778977   \n",
       "1       0.079651         0.004593         0.642203          0.783669   \n",
       "2       0.156604         0.008930         0.645046          0.783199   \n",
       "3       0.042447         0.002823         0.772805          0.966819   \n",
       "4       0.082083         0.004693         0.779033          0.967569   \n",
       "\n",
       "  param_criterion param_max_depth param_n_estimators  \\\n",
       "0             mse               2                 50   \n",
       "1             mse               2                100   \n",
       "2             mse               2                200   \n",
       "3             mse               6                 50   \n",
       "4             mse               6                100   \n",
       "\n",
       "                                              params  rank_test_score  \\\n",
       "0  {'criterion': 'mse', 'max_depth': 2, 'n_estima...               15   \n",
       "1  {'criterion': 'mse', 'max_depth': 2, 'n_estima...               14   \n",
       "2  {'criterion': 'mse', 'max_depth': 2, 'n_estima...               13   \n",
       "3  {'criterion': 'mse', 'max_depth': 6, 'n_estima...                6   \n",
       "4  {'criterion': 'mse', 'max_depth': 6, 'n_estima...                3   \n",
       "\n",
       "   split0_test_score       ...         split2_test_score  split2_train_score  \\\n",
       "0           0.613964       ...                  0.451744            0.804077   \n",
       "1           0.632470       ...                  0.452446            0.807411   \n",
       "2           0.646579       ...                  0.453979            0.809105   \n",
       "3           0.779761       ...                  0.534255            0.973722   \n",
       "4           0.771612       ...                  0.537566            0.973433   \n",
       "\n",
       "   split3_test_score  split3_train_score  split4_test_score  \\\n",
       "0           0.656762            0.758853           0.675603   \n",
       "1           0.661534            0.761985           0.677862   \n",
       "2           0.664311            0.762408           0.674158   \n",
       "3           0.834329            0.969750           0.826922   \n",
       "4           0.843001            0.968763           0.847150   \n",
       "\n",
       "   split4_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0            0.792493      0.004595        0.000730        0.107580   \n",
       "1            0.795574      0.003166        0.000032        0.109303   \n",
       "2            0.792468      0.003978        0.000223        0.108315   \n",
       "3            0.963078      0.001884        0.000285        0.125263   \n",
       "4            0.964772      0.002411        0.000024        0.128224   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.016929  \n",
       "1         0.016629  \n",
       "2         0.016699  \n",
       "3         0.004298  \n",
       "4         0.003374  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=grid_cv_regr.cv_results_)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46875"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It feels as if what we did here was comparing apples and oranges. Comparing apples with apples would be more like, did dow jones increase? did google search frequency increase? a score around 50 percent is actually a likely result here, because this is a binary target, and nothing in my features say anything about the previous day. Here we are taking a bunch of values and trying to figure out weather these values were higher or lower than the previous day, but we have no information about the previous day in our dfeatures matrix. For example when looking at one line of data from our features matrix, does any cell in this line tell us something about the previous day? On any given line how does it compare to the one before it? All these values are independent from the day before, acording to my model, because we are not saying how they are related.\n",
    "\n",
    "Now we will explore another idea for a classifier. For every single feature, make it an up or down binary vector. We should get way better results because we are not simply flipping a coin anymore. The binary of dow jones having gone up or down up or down should be more predictive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Classification with binary features:\n",
    "first we will make some binary features from lists utilizing the enumerate function. What the binary representation will indicate is the following: if the value went up from the day before we will attribute a 1 to that value. Each element in the vector is saying something about what direction price went from the day before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rise_fall_list_DJI = []\n",
    "\n",
    "for index, item in enumerate(df_ultra_mega_frame['DJI']):\n",
    "    if df_ultra_mega_frame['DJI'].iloc[index-1] < df_ultra_mega_frame['DJI'].iloc[index]:\n",
    "        rise_fall_list_DJI.append(1)\n",
    "    else:\n",
    "        rise_fall_list_DJI.append(0)\n",
    "        \n",
    "\n",
    "df_ultra_mega_frame['rise_lower_dji'] = rise_fall_list_DJI\n",
    "\n",
    "#--------\n",
    "rise_fall_list_BTC = []\n",
    "\n",
    "for index, item in enumerate(df_ultra_mega_frame['price_btc']):\n",
    "    if df_ultra_mega_frame['price_btc'].iloc[index-1] < df_ultra_mega_frame['price_btc'].iloc[index]:\n",
    "        rise_fall_list_BTC.append(1)\n",
    "    else:\n",
    "        rise_fall_list_BTC.append(0)\n",
    "        \n",
    "\n",
    "df_ultra_mega_frame['rise_lower_btc'] = rise_fall_list_BTC\n",
    "\n",
    "#---------\n",
    "rise_fall_list_SF = []\n",
    "\n",
    "for index, item in enumerate(df_ultra_mega_frame['SearchFrequency']):\n",
    "    if df_ultra_mega_frame['SearchFrequency'].iloc[index-1] < df_ultra_mega_frame['SearchFrequency'].iloc[index]:\n",
    "        rise_fall_list_SF.append(1)\n",
    "    else:\n",
    "        rise_fall_list_SF.append(0)\n",
    "        \n",
    "\n",
    "df_ultra_mega_frame['rise_lower_sf'] = rise_fall_list_SF\n",
    "\n",
    "df_ultra_mega_frame = df_ultra_mega_frame['2017-11-17':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that at the bottom of this code block we chop off the first line of the data frame because at this pint we are only dealing with the binary features and we do not have information to say whether the first element of our data set rose in price or fell in price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df_ultra_mega_frame['rise_lower'] #setting our label y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array(df_ultra_mega_frame['rise_lower'])\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= df_ultra_mega_frame.filter(['rise_lower_dji','rise_lower_btc','rise_lower_sf'], axis = 1)\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns) #this way we remeber the column names\n",
    "# Convert to numpy array\n",
    "X = np.array(features) #because once we convert to np array it drops the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12937936, 0.78567976, 0.08494088])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6875"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [2, 6, 8], 'n_estimators': [50, 100, 200]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use a grid search\n",
    "\n",
    "param_grid = {#\"criterion\": [\"mse\", \"mae\"], #mean squared error and mean absolute error in documentation\n",
    "              #\"min_samples_split\": [10, 20, 40],\n",
    "              \"max_depth\": [2, 6, 8],\n",
    "              \"n_estimators\":[50, 100, 200]\n",
    "              #\"min_samples_leaf\": [20, 40, 100],\n",
    "              #\"max_leaf_nodes\": [5, 20, 100, 500, 800],\n",
    "              }\n",
    "\n",
    "grid_cv_clf = GridSearchCV(clf, param_grid, cv=5)\n",
    "\n",
    "grid_cv_clf.fit(X_train, Y_train) #features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Squared::0.781573998077793\n",
      "Best Hyperparameters::\n",
      "{'criterion': 'mse', 'max_depth': 8, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(\"R-Squared::{}\".format(grid_cv_regr.best_score_))\n",
    "print(\"Best Hyperparameters::\\n{}\".format(grid_cv_regr.best_params_))\n",
    "\n",
    "#random forest builds multiple decision trees \n",
    "#best number of decision trees\n",
    "#depth of each tree shouldnt be more than 8 levels\n",
    "#go down to 8 levels(splits) but dont split it further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.047817</td>\n",
       "      <td>0.003355</td>\n",
       "      <td>0.635309</td>\n",
       "      <td>0.778977</td>\n",
       "      <td>mse</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.613964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451744</td>\n",
       "      <td>0.804077</td>\n",
       "      <td>0.656762</td>\n",
       "      <td>0.758853</td>\n",
       "      <td>0.675603</td>\n",
       "      <td>0.792493</td>\n",
       "      <td>0.004595</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.107580</td>\n",
       "      <td>0.016929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.079651</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>0.642203</td>\n",
       "      <td>0.783669</td>\n",
       "      <td>mse</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.632470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452446</td>\n",
       "      <td>0.807411</td>\n",
       "      <td>0.661534</td>\n",
       "      <td>0.761985</td>\n",
       "      <td>0.677862</td>\n",
       "      <td>0.795574</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.109303</td>\n",
       "      <td>0.016629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.156604</td>\n",
       "      <td>0.008930</td>\n",
       "      <td>0.645046</td>\n",
       "      <td>0.783199</td>\n",
       "      <td>mse</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>13</td>\n",
       "      <td>0.646579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453979</td>\n",
       "      <td>0.809105</td>\n",
       "      <td>0.664311</td>\n",
       "      <td>0.762408</td>\n",
       "      <td>0.674158</td>\n",
       "      <td>0.792468</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.108315</td>\n",
       "      <td>0.016699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.042447</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>0.772805</td>\n",
       "      <td>0.966819</td>\n",
       "      <td>mse</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'n_estima...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.779761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534255</td>\n",
       "      <td>0.973722</td>\n",
       "      <td>0.834329</td>\n",
       "      <td>0.969750</td>\n",
       "      <td>0.826922</td>\n",
       "      <td>0.963078</td>\n",
       "      <td>0.001884</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.125263</td>\n",
       "      <td>0.004298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.082083</td>\n",
       "      <td>0.004693</td>\n",
       "      <td>0.779033</td>\n",
       "      <td>0.967569</td>\n",
       "      <td>mse</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'n_estima...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.771612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537566</td>\n",
       "      <td>0.973433</td>\n",
       "      <td>0.843001</td>\n",
       "      <td>0.968763</td>\n",
       "      <td>0.847150</td>\n",
       "      <td>0.964772</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.128224</td>\n",
       "      <td>0.003374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.047817         0.003355         0.635309          0.778977   \n",
       "1       0.079651         0.004593         0.642203          0.783669   \n",
       "2       0.156604         0.008930         0.645046          0.783199   \n",
       "3       0.042447         0.002823         0.772805          0.966819   \n",
       "4       0.082083         0.004693         0.779033          0.967569   \n",
       "\n",
       "  param_criterion param_max_depth param_n_estimators  \\\n",
       "0             mse               2                 50   \n",
       "1             mse               2                100   \n",
       "2             mse               2                200   \n",
       "3             mse               6                 50   \n",
       "4             mse               6                100   \n",
       "\n",
       "                                              params  rank_test_score  \\\n",
       "0  {'criterion': 'mse', 'max_depth': 2, 'n_estima...               15   \n",
       "1  {'criterion': 'mse', 'max_depth': 2, 'n_estima...               14   \n",
       "2  {'criterion': 'mse', 'max_depth': 2, 'n_estima...               13   \n",
       "3  {'criterion': 'mse', 'max_depth': 6, 'n_estima...                6   \n",
       "4  {'criterion': 'mse', 'max_depth': 6, 'n_estima...                3   \n",
       "\n",
       "   split0_test_score       ...         split2_test_score  split2_train_score  \\\n",
       "0           0.613964       ...                  0.451744            0.804077   \n",
       "1           0.632470       ...                  0.452446            0.807411   \n",
       "2           0.646579       ...                  0.453979            0.809105   \n",
       "3           0.779761       ...                  0.534255            0.973722   \n",
       "4           0.771612       ...                  0.537566            0.973433   \n",
       "\n",
       "   split3_test_score  split3_train_score  split4_test_score  \\\n",
       "0           0.656762            0.758853           0.675603   \n",
       "1           0.661534            0.761985           0.677862   \n",
       "2           0.664311            0.762408           0.674158   \n",
       "3           0.834329            0.969750           0.826922   \n",
       "4           0.843001            0.968763           0.847150   \n",
       "\n",
       "   split4_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0            0.792493      0.004595        0.000730        0.107580   \n",
       "1            0.795574      0.003166        0.000032        0.109303   \n",
       "2            0.792468      0.003978        0.000223        0.108315   \n",
       "3            0.963078      0.001884        0.000285        0.125263   \n",
       "4            0.964772      0.002411        0.000024        0.128224   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.016929  \n",
       "1         0.016629  \n",
       "2         0.016699  \n",
       "3         0.004298  \n",
       "4         0.003374  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=grid_cv_regr.cv_results_)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6875"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_clf.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here hyperparameterization did not improve!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
