{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "import prawcore\n",
    "\n",
    "reddit = praw.Reddit(client_id = 'GeSMulGZbc7PeQ', client_secret = 'uSFY4s3PyufZwc9oHpIVlXpgI5Q', user_agent = 'scrapedata5')\n",
    "\n",
    "subreddit1 = reddit.subreddit('ethereum')\n",
    "submissions = subreddit1.submissions(1517619814,1517965414)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#timestamps will now go from mid-December 2017 to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reddits = []\n",
    "for submission in submissions:\n",
    "    post_id = submission.id\n",
    "    post_title = submission.title if submission.title else ''\n",
    "    # assuming it has a body\n",
    "    post_body = submission.selftext if submission.selftext else ''\n",
    "    post_text = post_title + ' ' + post_body\n",
    "    post_time = submission.created\n",
    "    post_type = 'post'\n",
    "    post_doc = {'doc_id': post_id,\n",
    "                'text': post_text,\n",
    "                'timestamp': post_time,\n",
    "                'doc_type': 'post'}\n",
    "    \n",
    "    reddits.append(post_doc)\n",
    "    \n",
    "    #we append to the main list first, then deal with the nesting\n",
    "    \n",
    "    top_level_comments = [comm for comm in submission.comments]\n",
    "    if top_level_comments:\n",
    "        for tlc in top_level_comments:\n",
    "            post_text = tlc.body \n",
    "            post_time = tlc.created\n",
    "            post_doc = {'doc_id': post_id,\n",
    "                        'text': post_text,\n",
    "                        'timestamp': post_time,\n",
    "                        'doc_type': 'comment'}\n",
    "            reddits.append(post_doc)\n",
    "            second_level_comments = [comm for comm in tlc.replies]\n",
    "            if second_level_comments:\n",
    "                for slc in second_level_comments:\n",
    "                    post_text = slc.body \n",
    "                    post_time = slc.created\n",
    "                    post_doc = {'doc_id': post_id,\n",
    "                                'text': post_text,\n",
    "                                'timestamp': post_time,\n",
    "                                'doc_type': 'comment'}\n",
    "                    reddits.append(post_doc)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(reddits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>doc_type</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7vrbwq</td>\n",
       "      <td>post</td>\n",
       "      <td>When is ethereum expected to switch to pos?</td>\n",
       "      <td>1.517986e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7vrbwq</td>\n",
       "      <td>comment</td>\n",
       "      <td>My estimate is Q3 2019</td>\n",
       "      <td>1.518024e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7vrbwq</td>\n",
       "      <td>comment</td>\n",
       "      <td>Thank you for the estimate! Just to clarify, i...</td>\n",
       "      <td>1.518030e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7vrbwq</td>\n",
       "      <td>comment</td>\n",
       "      <td>What are the bottlenecks?</td>\n",
       "      <td>1.518031e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7vrbwq</td>\n",
       "      <td>comment</td>\n",
       "      <td>There is no official date yet.   It appears th...</td>\n",
       "      <td>1.517987e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7vrbwq</td>\n",
       "      <td>comment</td>\n",
       "      <td>Do we know what the minimum stake will be?</td>\n",
       "      <td>1.517991e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7vrbwq</td>\n",
       "      <td>comment</td>\n",
       "      <td>I'm hoping they will increase a lot in value. ...</td>\n",
       "      <td>1.518053e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7vrbwq</td>\n",
       "      <td>comment</td>\n",
       "      <td>Soon, start stacking.</td>\n",
       "      <td>1.517988e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7vrbwq</td>\n",
       "      <td>comment</td>\n",
       "      <td>In 2016.</td>\n",
       "      <td>1.518046e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7vrbwq</td>\n",
       "      <td>comment</td>\n",
       "      <td>This is literally why I still am 60% BTC and o...</td>\n",
       "      <td>1.518008e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7vrbwq</td>\n",
       "      <td>comment</td>\n",
       "      <td>Well, it never bothered Americans using USD, t...</td>\n",
       "      <td>1.518016e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7vrbwq</td>\n",
       "      <td>comment</td>\n",
       "      <td>You will be long dead before Bitcoin issuance ...</td>\n",
       "      <td>1.518048e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7vrbwq</td>\n",
       "      <td>comment</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>1.518048e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7vrbwq</td>\n",
       "      <td>comment</td>\n",
       "      <td>How would proof of stake lead to 'potentially ...</td>\n",
       "      <td>1.518050e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7vr6wk</td>\n",
       "      <td>post</td>\n",
       "      <td>mBitCasino to accept Ethereum deposits/withdra...</td>\n",
       "      <td>1.517984e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7vr67i</td>\n",
       "      <td>post</td>\n",
       "      <td>Making a crypto utopia in Puerto Rico</td>\n",
       "      <td>1.517984e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7vr67i</td>\n",
       "      <td>comment</td>\n",
       "      <td>Puerto Rico, the first Bitcoin Citadel!  Life ...</td>\n",
       "      <td>1.518005e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7vr67i</td>\n",
       "      <td>comment</td>\n",
       "      <td>Yeah, despicable bullshit from noveau riche as...</td>\n",
       "      <td>1.518017e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7vr67i</td>\n",
       "      <td>comment</td>\n",
       "      <td>Puerto Rico has some interesting tax incentive...</td>\n",
       "      <td>1.517986e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7vr67i</td>\n",
       "      <td>comment</td>\n",
       "      <td>Any venture involving Brock Pierce so proemine...</td>\n",
       "      <td>1.518022e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    doc_id doc_type                                               text  \\\n",
       "0   7vrbwq     post       When is ethereum expected to switch to pos?    \n",
       "1   7vrbwq  comment                             My estimate is Q3 2019   \n",
       "2   7vrbwq  comment  Thank you for the estimate! Just to clarify, i...   \n",
       "3   7vrbwq  comment                          What are the bottlenecks?   \n",
       "4   7vrbwq  comment  There is no official date yet.   It appears th...   \n",
       "5   7vrbwq  comment         Do we know what the minimum stake will be?   \n",
       "6   7vrbwq  comment  I'm hoping they will increase a lot in value. ...   \n",
       "7   7vrbwq  comment                              Soon, start stacking.   \n",
       "8   7vrbwq  comment                                           In 2016.   \n",
       "9   7vrbwq  comment  This is literally why I still am 60% BTC and o...   \n",
       "10  7vrbwq  comment  Well, it never bothered Americans using USD, t...   \n",
       "11  7vrbwq  comment  You will be long dead before Bitcoin issuance ...   \n",
       "12  7vrbwq  comment                                          [deleted]   \n",
       "13  7vrbwq  comment  How would proof of stake lead to 'potentially ...   \n",
       "14  7vr6wk     post  mBitCasino to accept Ethereum deposits/withdra...   \n",
       "15  7vr67i     post             Making a crypto utopia in Puerto Rico    \n",
       "16  7vr67i  comment  Puerto Rico, the first Bitcoin Citadel!  Life ...   \n",
       "17  7vr67i  comment  Yeah, despicable bullshit from noveau riche as...   \n",
       "18  7vr67i  comment  Puerto Rico has some interesting tax incentive...   \n",
       "19  7vr67i  comment  Any venture involving Brock Pierce so proemine...   \n",
       "\n",
       "       timestamp  \n",
       "0   1.517986e+09  \n",
       "1   1.518024e+09  \n",
       "2   1.518030e+09  \n",
       "3   1.518031e+09  \n",
       "4   1.517987e+09  \n",
       "5   1.517991e+09  \n",
       "6   1.518053e+09  \n",
       "7   1.517988e+09  \n",
       "8   1.518046e+09  \n",
       "9   1.518008e+09  \n",
       "10  1.518016e+09  \n",
       "11  1.518048e+09  \n",
       "12  1.518048e+09  \n",
       "13  1.518050e+09  \n",
       "14  1.517984e+09  \n",
       "15  1.517984e+09  \n",
       "16  1.518005e+09  \n",
       "17  1.518017e+09  \n",
       "18  1.517986e+09  \n",
       "19  1.518022e+09  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/Alexandra/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'words.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d534546049c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'words.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'words.txt'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import csv\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "para = \"What can I say about this place. The staff of the restaurant is nice and the eggplant is not bad. Apart from that, very uninspired food, lack of atmosphere and too expensive. I am a staunch vegetarian and was sorely dissapointed with the veggie options on the menu. Will be the last time I visit, I recommend others to avoid\"\n",
    "\n",
    "sentense = word_tokenize(para)\n",
    "word_features = []\n",
    "\n",
    "for i,j in nltk.pos_tag(sentense):\n",
    "    if j in ['JJ', 'JJR', 'JJS', 'RB', 'RBR', 'RBS']: \n",
    "        word_features.append(i)\n",
    "\n",
    "rating = 0\n",
    "\n",
    "for i in word_features:\n",
    "    with open('words.txt', 'rt') as f:\n",
    "        reader = csv.reader(f, delimiter=',')\n",
    "        for row in reader:\n",
    "            if i == row[0]:\n",
    "                print(i, row[1])\n",
    "                if row[1] == 'pos':\n",
    "                    rating = rating + 1\n",
    "                elif row[1] == 'neg':\n",
    "                    rating = rating - 1\n",
    "print(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fc62de1987ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtext_normalizer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Alexandra/Desktop/sentAnalysis_onMyData/text_normalizer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# # Import necessary dependencies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoktok\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mToktokTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import text_normalizer as tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyze_sentiment_vader_lexicon(review, \n",
    "                                    threshold=0.1,\n",
    "                                    verbose=False):\n",
    "    # pre-process text\n",
    "    review = tn.strip_html_tags(review)\n",
    "    review = tn.remove_accented_chars(review)\n",
    "    review = tn.expand_contractions(review)\n",
    "    \n",
    "    # analyze the sentiment for review\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(review)\n",
    "    # get aggregate scores and final sentiment\n",
    "    agg_score = scores['compound']\n",
    "    final_sentiment = 'positive' if agg_score >= threshold\\\n",
    "                                   else 'negative'\n",
    "    if verbose:\n",
    "        # display detailed sentiment statistics\n",
    "        positive = str(round(scores['pos'], 2)*100)+'%'\n",
    "        final = round(agg_score, 2)\n",
    "        negative = str(round(scores['neg'], 2)*100)+'%'\n",
    "        neutral = str(round(scores['neu'], 2)*100)+'%'\n",
    "        sentiment_frame = pd.DataFrame([[final_sentiment, final, positive,\n",
    "                                        negative, neutral]],\n",
    "                                        columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'], \n",
    "                                                                      ['Predicted Sentiment', 'Polarity Score',\n",
    "                                                                       'Positive', 'Negative', 'Neutral']], \n",
    "                                                              labels=[[0,0,0,0,0],[0,1,2,3,4]]))\n",
    "        print(sentiment_frame)\n",
    "    \n",
    "    return final_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e9535a50afc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredicted_sentiments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0manalyze_sentiment_vader_lexicon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "predicted_sentiments = [analyze_sentiment_vader_lexicon(review, threshold=0.4, verbose=False) for review in df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
